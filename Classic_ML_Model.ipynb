{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "seed = 42\n",
    "pca = None\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>007</th>\n",
       "      <th>007 (series)</th>\n",
       "      <th>18th century</th>\n",
       "      <th>1920s</th>\n",
       "      <th>1930s</th>\n",
       "      <th>1950s</th>\n",
       "      <th>1960s</th>\n",
       "      <th>1970s</th>\n",
       "      <th>1980s</th>\n",
       "      <th>...</th>\n",
       "      <th>world war i</th>\n",
       "      <th>world war ii</th>\n",
       "      <th>writer's life</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>wuxia</th>\n",
       "      <th>wwii</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.893708</td>\n",
       "      <td>0.02875</td>\n",
       "      <td>0.02375</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.07575</td>\n",
       "      <td>0.14075</td>\n",
       "      <td>0.14675</td>\n",
       "      <td>0.06350</td>\n",
       "      <td>0.20375</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01425</td>\n",
       "      <td>0.03050</td>\n",
       "      <td>0.03500</td>\n",
       "      <td>0.14125</td>\n",
       "      <td>0.05775</td>\n",
       "      <td>0.03900</td>\n",
       "      <td>0.02975</td>\n",
       "      <td>0.08475</td>\n",
       "      <td>0.02200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.251527</td>\n",
       "      <td>0.04125</td>\n",
       "      <td>0.04050</td>\n",
       "      <td>0.06275</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.09100</td>\n",
       "      <td>0.06125</td>\n",
       "      <td>0.06925</td>\n",
       "      <td>0.09600</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01575</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.12225</td>\n",
       "      <td>0.03275</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>0.01100</td>\n",
       "      <td>0.10525</td>\n",
       "      <td>0.01975</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.142028</td>\n",
       "      <td>0.04675</td>\n",
       "      <td>0.05550</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>0.08700</td>\n",
       "      <td>0.04750</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0.04600</td>\n",
       "      <td>0.14275</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01950</td>\n",
       "      <td>0.02225</td>\n",
       "      <td>0.02300</td>\n",
       "      <td>0.12200</td>\n",
       "      <td>0.03475</td>\n",
       "      <td>0.01700</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.09100</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.853547</td>\n",
       "      <td>0.03425</td>\n",
       "      <td>0.03800</td>\n",
       "      <td>0.04050</td>\n",
       "      <td>0.03100</td>\n",
       "      <td>0.06500</td>\n",
       "      <td>0.03575</td>\n",
       "      <td>0.02900</td>\n",
       "      <td>0.08650</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>0.01675</td>\n",
       "      <td>0.03875</td>\n",
       "      <td>0.18200</td>\n",
       "      <td>0.07050</td>\n",
       "      <td>0.01625</td>\n",
       "      <td>0.01425</td>\n",
       "      <td>0.08850</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.058434</td>\n",
       "      <td>0.04300</td>\n",
       "      <td>0.05325</td>\n",
       "      <td>0.03800</td>\n",
       "      <td>0.04100</td>\n",
       "      <td>0.05400</td>\n",
       "      <td>0.06725</td>\n",
       "      <td>0.02775</td>\n",
       "      <td>0.07650</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02050</td>\n",
       "      <td>0.01425</td>\n",
       "      <td>0.02550</td>\n",
       "      <td>0.19225</td>\n",
       "      <td>0.02675</td>\n",
       "      <td>0.01625</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>0.08700</td>\n",
       "      <td>0.01600</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating      007  007 (series)  18th century    1920s    1930s    1950s   \n",
       "0  3.893708  0.02875       0.02375       0.06250  0.07575  0.14075  0.14675  \\\n",
       "1  3.251527  0.04125       0.04050       0.06275  0.08275  0.09100  0.06125   \n",
       "2  3.142028  0.04675       0.05550       0.02925  0.08700  0.04750  0.04775   \n",
       "3  2.853547  0.03425       0.03800       0.04050  0.03100  0.06500  0.03575   \n",
       "4  3.058434  0.04300       0.05325       0.03800  0.04100  0.05400  0.06725   \n",
       "\n",
       "     1960s    1970s   1980s  ...  world war i  world war ii  writer's life   \n",
       "0  0.06350  0.20375  0.2020  ...      0.01425       0.03050        0.03500  \\\n",
       "1  0.06925  0.09600  0.0765  ...      0.01575       0.01250        0.02000   \n",
       "2  0.04600  0.14275  0.0285  ...      0.01950       0.02225        0.02300   \n",
       "3  0.02900  0.08650  0.0320  ...      0.02800       0.01675        0.03875   \n",
       "4  0.02775  0.07650  0.0215  ...      0.02050       0.01425        0.02550   \n",
       "\n",
       "   writers  writing    wuxia     wwii   zombie  zombies  year  \n",
       "0  0.14125  0.05775  0.03900  0.02975  0.08475  0.02200  None  \n",
       "1  0.12225  0.03275  0.02100  0.01100  0.10525  0.01975  None  \n",
       "2  0.12200  0.03475  0.01700  0.01800  0.09100  0.01775  None  \n",
       "3  0.18200  0.07050  0.01625  0.01425  0.08850  0.01500  None  \n",
       "4  0.19225  0.02675  0.01625  0.01300  0.08700  0.01600  None  \n",
       "\n",
       "[5 rows x 1130 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2_normalization\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rating_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rating_count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m columns_to_transform:\n\u001b[0;32m     12\u001b[0m         df[column] \u001b[39m=\u001b[39m transform(df[column])\n\u001b[1;32m---> 14\u001b[0m normalize(df, \u001b[39m'\u001b[39;49m\u001b[39mL2_normalization\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(df, type)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m columns_to_transform:\n\u001b[1;32m---> 12\u001b[0m     df[column] \u001b[39m=\u001b[39m transform(df[column])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3759\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3760\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3761\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3762\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rating_count'"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_transform = ['year', 'rating_count']\n",
    "\n",
    "\n",
    "def transform(X):\n",
    "            X_norm2 = np.linalg.norm(X, ord=2)\n",
    "            X = X / X_norm2\n",
    "\n",
    "\n",
    "def normalize(df, type):\n",
    "    print(type)\n",
    "    for column in columns_to_transform:\n",
    "        df[column] = transform(df[column])\n",
    "\n",
    "normalize(df, 'L2_normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataframe df into train and test\n",
    "X=df.drop(['rating'],axis=1)\n",
    "y=df['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: (9946, 1128)\n",
      "Number of testing samples: (2764, 1128)\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training samples: {X_train.shape}')\n",
    "print(f'Number of testing samples: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_val = pca.transform(X_val)\n",
    "X_test = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R2 score: 0.9709615407207532\n",
      "Linear Regression MSE: 0.0064368418369928765\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'Linear Regression R2 score: {model.score(X_test, y_test)}')\n",
    "print(f'Linear Regression MSE: {mean_squared_error(y_test, model.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 3\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 1105\n",
      "max_resources_: 9946\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 9\n",
      "n_resources: 1105\n",
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.035, test=-0.069) total time=   1.4s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.029, test=-0.067) total time=   1.4s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.031, test=-0.062) total time=   6.9s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.027, test=-0.064) total time=   6.9s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.030, test=-0.061) total time=  14.2s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.026, test=-0.062) total time=  14.2s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.122, test=-0.190) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.095, test=-0.154) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.116, test=-0.173) total time=   0.3s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.097, test=-0.144) total time=   0.3s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.113, test=-0.173) total time=   0.7s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.104, test=-0.158) total time=   0.7s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.142, test=-0.184) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.117, test=-0.165) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.150, test=-0.209) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.124, test=-0.178) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.144, test=-0.200) total time=   0.3s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.121, test=-0.173) total time=   0.3s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 3\n",
      "n_resources: 3315\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.040, test=-0.061) total time=   4.6s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.042, test=-0.062) total time=   4.4s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.038, test=-0.060) total time=  23.0s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.040, test=-0.061) total time=  25.0s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.038, test=-0.059) total time=  45.3s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.040, test=-0.061) total time=  46.2s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 1\n",
      "n_resources: 9945\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.047, test=-0.058) total time= 2.5min\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.048, test=-0.056) total time= 2.4min\n",
      "\n",
      "Best MSE: 0.057063\n",
      "Best parameters: {'max_depth': 5, 'max_features': 1.0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters tuning for random forest regressor\n",
    "model=RandomForestRegressor()\n",
    "\n",
    "#generate random number\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [5],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [2],\n",
    "    'max_features': [1.0, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "hgs = HalvingGridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, random_state=rng, verbose=3, cv=2, scoring='neg_mean_squared_error'\n",
    ")\n",
    "hgs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\nBest MSE: {:.6f}\".format(-hgs.best_score_))\n",
    "print(\"Best parameters: {}\".format(hgs.best_params_))\n",
    "\n",
    "\n",
    "#hgs_results = plot_model_results(hgs, 'RandomForestRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration: 1/30 - N_estimator: 50 - Criterion: squared_error - MSE: 0.0335 - Best MSE: 0.0335\n",
      " Iteration: 2/30 - N_estimator: 50 - Criterion: friedman_mse - MSE: 0.0340 - Best MSE: 0.0335\n",
      " Iteration: 3/30 - N_estimator: 50 - Criterion: poisson - MSE: 0.0345 - Best MSE: 0.0335\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m writer \u001b[39m=\u001b[39m SummaryWriter(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mclassicML/RFR/\u001b[39m\u001b[39m{\u001b[39;00mlog_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m rf \u001b[39m=\u001b[39m RandomForestRegressor(n_estimators\u001b[39m=\u001b[39mn, criterion\u001b[39m=\u001b[39mc)\n\u001b[1;32m---> 21\u001b[0m rf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     22\u001b[0m Y_pred \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mpredict(X_val)\n\u001b[0;32m     23\u001b[0m mse \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean((Y_pred \u001b[39m-\u001b[39m y_val)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "n_tree = [ i for i in range(50, 100, 5)]\n",
    "criterion = [\"squared_error\", \"friedman_mse\", \"poisson\"]\n",
    "\n",
    "rfr_best_mse = float('inf')\n",
    "rfr_best_n = None\n",
    "rfr_best_c = None\n",
    "rfr_best = None\n",
    "\n",
    "i = 0\n",
    "max_iter = len(n_tree) * len(criterion)\n",
    "\n",
    "history_rfr = []\n",
    "\n",
    "for n, c in itertools.product(n_tree, criterion):\n",
    "    i += 1\n",
    "    log_name = f\"n_estimators={n}, criterion={c}\"\n",
    "    writer = SummaryWriter(f\"classicML/RFR/{log_name}\")\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=n, criterion=c)\n",
    "    rf.fit(X_train, y_train)\n",
    "    Y_pred = rf.predict(X_val)\n",
    "    mse = np.mean((Y_pred - y_val)**2)\n",
    "\n",
    "    history_rfr.append([n, c, mse])\n",
    "\n",
    "    writer.add_scalar('Loss', mse, n)\n",
    "    writer.add_hparams(\n",
    "        {'n_estimators': n, 'criterion': c},\n",
    "        {'mse': mse}\n",
    "    )\n",
    "    writer.flush()\n",
    "\n",
    "    if mse < rfr_best_mse:\n",
    "        rfr_best_mse = mse\n",
    "        rfr_best_n = n\n",
    "        rfr_best_c = c\n",
    "        rfr_best = copy.deepcopy(rf)\n",
    "    \n",
    "    print(\" Iteration: {}/{} - N_estimator: {} - Criterion: {} - MSE: {:.4f} - Best MSE: {:.4f}\".format(i, max_iter, n, c, mse, rfr_best_mse))\n",
    "\n",
    "Y_pred = rfr_best.predict(X_test)\n",
    "rf_r2 = r2_score(y_test, Y_pred)\n",
    "\n",
    "print(\"\\nRFR Hyperparameter Tuning Results\")\n",
    "print(\" - N estimators: \", rfr_best_n)\n",
    "print(\" - Criterion: \", rfr_best_c)\n",
    "print(\" - MSE: \", rfr_best_mse)\n",
    "print(\" - R2: \", rf_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
