{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "seed = 42\n",
    "pca = None\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>007</th>\n",
       "      <th>007 (series)</th>\n",
       "      <th>18th century</th>\n",
       "      <th>1920s</th>\n",
       "      <th>1930s</th>\n",
       "      <th>1950s</th>\n",
       "      <th>1960s</th>\n",
       "      <th>1970s</th>\n",
       "      <th>...</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.893708</td>\n",
       "      <td>57309</td>\n",
       "      <td>0.02875</td>\n",
       "      <td>0.02375</td>\n",
       "      <td>0.06250</td>\n",
       "      <td>0.07575</td>\n",
       "      <td>0.14075</td>\n",
       "      <td>0.14675</td>\n",
       "      <td>0.06350</td>\n",
       "      <td>0.20375</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.251527</td>\n",
       "      <td>24228</td>\n",
       "      <td>0.04125</td>\n",
       "      <td>0.04050</td>\n",
       "      <td>0.06275</td>\n",
       "      <td>0.08275</td>\n",
       "      <td>0.09100</td>\n",
       "      <td>0.06125</td>\n",
       "      <td>0.06925</td>\n",
       "      <td>0.09600</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.142028</td>\n",
       "      <td>11804</td>\n",
       "      <td>0.04675</td>\n",
       "      <td>0.05550</td>\n",
       "      <td>0.02925</td>\n",
       "      <td>0.08700</td>\n",
       "      <td>0.04750</td>\n",
       "      <td>0.04775</td>\n",
       "      <td>0.04600</td>\n",
       "      <td>0.14275</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.853547</td>\n",
       "      <td>2523</td>\n",
       "      <td>0.03425</td>\n",
       "      <td>0.03800</td>\n",
       "      <td>0.04050</td>\n",
       "      <td>0.03100</td>\n",
       "      <td>0.06500</td>\n",
       "      <td>0.03575</td>\n",
       "      <td>0.02900</td>\n",
       "      <td>0.08650</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.058434</td>\n",
       "      <td>11714</td>\n",
       "      <td>0.04300</td>\n",
       "      <td>0.05325</td>\n",
       "      <td>0.03800</td>\n",
       "      <td>0.04100</td>\n",
       "      <td>0.05400</td>\n",
       "      <td>0.06725</td>\n",
       "      <td>0.02775</td>\n",
       "      <td>0.07650</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating  rating_count      007  007 (series)  18th century    1920s   \n",
       "0  3.893708         57309  0.02875       0.02375       0.06250  0.07575  \\\n",
       "1  3.251527         24228  0.04125       0.04050       0.06275  0.08275   \n",
       "2  3.142028         11804  0.04675       0.05550       0.02925  0.08700   \n",
       "3  2.853547          2523  0.03425       0.03800       0.04050  0.03100   \n",
       "4  3.058434         11714  0.04300       0.05325       0.03800  0.04100   \n",
       "\n",
       "     1930s    1950s    1960s    1970s  ...  Horror  IMAX  Musical  Mystery   \n",
       "0  0.14075  0.14675  0.06350  0.20375  ...       0     0        0        0  \\\n",
       "1  0.09100  0.06125  0.06925  0.09600  ...       0     0        0        0   \n",
       "2  0.04750  0.04775  0.04600  0.14275  ...       0     0        0        0   \n",
       "3  0.06500  0.03575  0.02900  0.08650  ...       0     0        0        0   \n",
       "4  0.05400  0.06725  0.02775  0.07650  ...       0     0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  year  \n",
       "0        0       0         0    0        0  1995  \n",
       "1        0       0         0    0        0  1995  \n",
       "2        1       0         0    0        0  1995  \n",
       "3        1       0         0    0        0  1995  \n",
       "4        0       0         0    0        0  1995  \n",
       "\n",
       "[5 rows x 1151 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2_normalization\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_to_transform = ['year', 'rating_count']\n",
    "\n",
    "\n",
    "def transform(X):\n",
    "    X_norm2 = np.linalg.norm(X, ord=2)\n",
    "    X = X / X_norm2\n",
    "    return X\n",
    "\n",
    "def normalize(df, type):\n",
    "    print(type)\n",
    "    for column in columns_to_transform:\n",
    "        df[column] = transform(df[column])\n",
    "    return df\n",
    "df=normalize(df, 'L2_normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting dataframe df into train and test\n",
    "X=df.drop(['rating'],axis=1)\n",
    "y=df['rating']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: (9934, 1150)\n",
      "Number of testing samples: (2760, 1150)\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training samples: {X_train.shape}')\n",
    "print(f'Number of testing samples: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_val = pca.transform(X_val)\n",
    "X_test = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R2 score: 0.9764271756767273\n",
      "Linear Regression MSE: 0.005317075058827069\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'Linear Regression R2 score: {model.score(X_test, y_test)}')\n",
    "print(f'Linear Regression MSE: {mean_squared_error(y_test, model.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 367\n",
      "max_resources_: 9934\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 54\n",
      "n_resources: 367\n",
      "Fitting 2 folds for each of 54 candidates, totalling 108 fits\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=(train=-0.010, test=-0.036) total time=   0.8s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=(train=-0.010, test=-0.044) total time=   0.8s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=-0.006, test=-0.031) total time=   3.9s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=-0.007, test=-0.030) total time=   4.0s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.006, test=-0.029) total time=   8.4s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.007, test=-0.031) total time=   8.2s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=10;, score=(train=-0.009, test=-0.036) total time=   0.9s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=10;, score=(train=-0.009, test=-0.036) total time=   0.8s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.006, test=-0.027) total time=   4.1s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.008, test=-0.032) total time=   4.1s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.006, test=-0.029) total time=   8.2s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.007, test=-0.033) total time=   8.3s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.011, test=-0.036) total time=   0.7s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.012, test=-0.039) total time=   0.7s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.007, test=-0.032) total time=   3.8s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.008, test=-0.031) total time=   3.8s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.006, test=-0.029) total time=   7.7s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.007, test=-0.033) total time=   7.8s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=10;, score=(train=-0.009, test=-0.040) total time=   0.7s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=10;, score=(train=-0.010, test=-0.036) total time=   0.7s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=(train=-0.007, test=-0.032) total time=   3.9s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=(train=-0.007, test=-0.032) total time=   4.0s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.006, test=-0.029) total time=   7.5s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.008, test=-0.031) total time=   7.4s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=10;, score=(train=-0.010, test=-0.035) total time=   0.7s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=10;, score=(train=-0.009, test=-0.038) total time=   0.6s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.007, test=-0.030) total time=   3.3s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.009, test=-0.031) total time=   3.5s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=(train=-0.007, test=-0.029) total time=   6.8s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=(train=-0.007, test=-0.031) total time=   6.6s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=(train=-0.010, test=-0.039) total time=   0.6s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=(train=-0.011, test=-0.043) total time=   0.6s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=(train=-0.007, test=-0.030) total time=   3.3s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=(train=-0.010, test=-0.035) total time=   3.3s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=100;, score=(train=-0.006, test=-0.027) total time=   6.7s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=100;, score=(train=-0.008, test=-0.029) total time=   6.7s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=(train=-0.018, test=-0.068) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=(train=-0.019, test=-0.053) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=-0.011, test=-0.047) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=-0.015, test=-0.043) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.010, test=-0.046) total time=   0.3s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.013, test=-0.039) total time=   0.3s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10;, score=(train=-0.016, test=-0.063) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=10;, score=(train=-0.017, test=-0.052) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.011, test=-0.049) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.017, test=-0.046) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.011, test=-0.046) total time=   0.3s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.014, test=-0.043) total time=   0.3s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.013, test=-0.045) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.018, test=-0.053) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.012, test=-0.051) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.015, test=-0.045) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.011, test=-0.049) total time=   0.2s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.013, test=-0.041) total time=   0.3s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10;, score=(train=-0.014, test=-0.045) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=10;, score=(train=-0.018, test=-0.057) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=(train=-0.012, test=-0.047) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=(train=-0.016, test=-0.044) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.012, test=-0.048) total time=   0.3s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.014, test=-0.041) total time=   0.3s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=10;, score=(train=-0.018, test=-0.052) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=10;, score=(train=-0.022, test=-0.055) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.012, test=-0.047) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.019, test=-0.042) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=(train=-0.012, test=-0.045) total time=   0.2s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=(train=-0.016, test=-0.043) total time=   0.2s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=(train=-0.020, test=-0.078) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=(train=-0.021, test=-0.042) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=(train=-0.014, test=-0.046) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=(train=-0.016, test=-0.042) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100;, score=(train=-0.012, test=-0.045) total time=   0.3s\n",
      "[CV 2/2] END max_depth=5, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=100;, score=(train=-0.017, test=-0.043) total time=   0.2s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=(train=-0.022, test=-0.061) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=(train=-0.023, test=-0.062) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=-0.015, test=-0.056) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=-0.019, test=-0.054) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.016, test=-0.059) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.020, test=-0.055) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10;, score=(train=-0.021, test=-0.069) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=10;, score=(train=-0.030, test=-0.079) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.016, test=-0.060) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.019, test=-0.055) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.016, test=-0.061) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.021, test=-0.056) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.024, test=-0.088) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.029, test=-0.064) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.018, test=-0.065) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.021, test=-0.053) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.017, test=-0.062) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.019, test=-0.053) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=10;, score=(train=-0.020, test=-0.073) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=10;, score=(train=-0.025, test=-0.050) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=(train=-0.017, test=-0.062) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=(train=-0.020, test=-0.055) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.017, test=-0.059) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.019, test=-0.053) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=10;, score=(train=-0.021, test=-0.053) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=10;, score=(train=-0.036, test=-0.062) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.022, test=-0.068) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.026, test=-0.057) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=(train=-0.019, test=-0.060) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=(train=-0.024, test=-0.052) total time=   0.1s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=(train=-0.025, test=-0.070) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=(train=-0.030, test=-0.070) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=(train=-0.022, test=-0.063) total time=   0.0s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=(train=-0.024, test=-0.052) total time=   0.0s\n",
      "[CV 1/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100;, score=(train=-0.019, test=-0.057) total time=   0.1s\n",
      "[CV 2/2] END max_depth=5, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=100;, score=(train=-0.024, test=-0.053) total time=   0.1s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 18\n",
      "n_resources: 1101\n",
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=(train=-0.010, test=-0.024) total time=   2.2s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=10;, score=(train=-0.009, test=-0.027) total time=   2.2s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=(train=-0.010, test=-0.025) total time=   2.3s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=10;, score=(train=-0.010, test=-0.030) total time=   2.3s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=10;, score=(train=-0.010, test=-0.024) total time=   2.2s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=10;, score=(train=-0.010, test=-0.030) total time=   2.3s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.009, test=-0.023) total time=   2.3s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=10;, score=(train=-0.010, test=-0.029) total time=   2.3s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=10;, score=(train=-0.010, test=-0.024) total time=   2.2s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=10;, score=(train=-0.010, test=-0.030) total time=   2.2s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=10;, score=(train=-0.010, test=-0.027) total time=   2.3s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=10;, score=(train=-0.009, test=-0.030) total time=   2.4s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=(train=-0.008, test=-0.023) total time=  11.5s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=50;, score=(train=-0.008, test=-0.027) total time=  11.4s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=(train=-0.008, test=-0.021) total time=  11.8s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=50;, score=(train=-0.008, test=-0.027) total time=  11.6s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.008, test=-0.021) total time=  11.6s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=(train=-0.008, test=-0.028) total time=  11.7s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.008, test=-0.022) total time=  23.4s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.007, test=-0.026) total time=  23.3s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.008, test=-0.021) total time=  24.0s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.007, test=-0.026) total time=  24.0s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=-0.008, test=-0.021) total time=  12.4s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=(train=-0.008, test=-0.027) total time=  12.0s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.008, test=-0.021) total time=  11.6s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.009, test=-0.026) total time=  11.6s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.008, test=-0.021) total time=  24.2s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.008, test=-0.026) total time=  24.1s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.008, test=-0.020) total time=  23.2s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.008, test=-0.026) total time=  23.1s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=(train=-0.008, test=-0.021) total time=  22.6s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=100;, score=(train=-0.008, test=-0.026) total time=  22.4s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.008, test=-0.021) total time=  11.8s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.008, test=-0.026) total time=  11.8s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=100;, score=(train=-0.008, test=-0.022) total time=  22.6s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=4, n_estimators=100;, score=(train=-0.008, test=-0.027) total time=  22.5s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 6\n",
      "n_resources: 3303\n",
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.013, test=-0.021) total time= 1.1min\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.013, test=-0.023) total time= 1.1min\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.013, test=-0.020) total time=  33.4s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.013, test=-0.023) total time=  33.6s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.013, test=-0.021) total time= 1.2min\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=(train=-0.013, test=-0.024) total time= 1.3min\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.013, test=-0.021) total time=  35.5s\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=50;, score=(train=-0.013, test=-0.024) total time=  34.4s\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.013, test=-0.021) total time= 1.2min\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=1, min_samples_split=4, n_estimators=100;, score=(train=-0.013, test=-0.024) total time= 1.2min\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.013, test=-0.021) total time= 1.2min\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=4, n_estimators=100;, score=(train=-0.013, test=-0.024) total time= 1.2min\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 9909\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.019, test=-0.021) total time= 3.2min\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=(train=-0.018, test=-0.024) total time= 3.1min\n",
      "[CV 1/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.020, test=-0.022) total time= 1.5min\n",
      "[CV 2/2] END max_depth=5, max_features=1.0, min_samples_leaf=3, min_samples_split=2, n_estimators=50;, score=(train=-0.019, test=-0.025) total time= 1.6min\n",
      "\n",
      "Best MSE: 0.022796\n",
      "Best parameters: {'max_depth': 5, 'max_features': 1.0, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters tuning for random forest regressor\n",
    "model=RandomForestRegressor()\n",
    "\n",
    "#generate random number\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [5],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': [1.0, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "hgs = HalvingGridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, random_state=rng, verbose=3, cv=2, scoring='neg_mean_squared_error'\n",
    ")\n",
    "hgs.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\nBest MSE: {:.6f}\".format(-hgs.best_score_))\n",
    "print(\"Best parameters: {}\".format(hgs.best_params_))\n",
    "\n",
    "\n",
    "#hgs_results = plot_model_results(hgs, 'RandomForestRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor R2 score: 0.9474482750240798\n",
      "Random Forest Regressor MSE: 0.011853542126979701\n"
     ]
    }
   ],
   "source": [
    "#train random forest regressor with best parameters\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=25,\n",
    "    min_samples_split=hgs.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=hgs.best_params_['min_samples_leaf'],\n",
    "    max_features=hgs.best_params_['max_features'],\n",
    "    random_state=rng\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'Random Forest Regressor R2 score: {model.score(X_test, y_test)}')\n",
    "print(f'Random Forest Regressor MSE: {mean_squared_error(y_test, model.predict(X_test))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GridSearchCV to find the best parameters for SVM\n",
    "model = SVR()\n",
    "\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'C': [0.01,0.1, 1, 10, 100],\n",
    "    'epsilon': [0.01, 0.1, , 0.5, 1, 5]\n",
    "}\n",
    "\n",
    "hgs = HalvingGridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, random_state=rng, verbose=3, cv=2, scoring='neg_mean_squared_error'\n",
    ")\n",
    "hgs.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest MSE: {:.6f}\".format(-hgs.best_score_))\n",
    "print(\"Best parameters: {}\".format(hgs.best_params_))\n",
    "\n",
    "#print the r2 results for the best parameters\n",
    "model = SVR(\n",
    "    kernel=hgs.best_params_['kernel'],\n",
    "    degree=hgs.best_params_['degree'],\n",
    "    gamma=hgs.best_params_['gamma'],\n",
    "    C=hgs.best_params_['C'],\n",
    "    epsilon=hgs.best_params_['epsilon']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'SVM R2 score: {model.score(X_test, y_test)}')\n",
    "print(f'SVM MSE: {mean_squared_error(y_test, model.predict(X_test))}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
