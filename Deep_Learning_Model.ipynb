{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, HalvingGridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def fix_random(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "fix_random(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# PyTorch Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('rating', axis=1)\n",
    "Y = df['rating']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_val = Y_val.to_numpy()\n",
    "Y_test = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_val = pca.transform(X_val)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 9934\n",
      "Number of validation samples: 1104\n",
      "Number of testing samples: 2760\n",
      "\n",
      "Number of features: 1148\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print(f'Number of validation samples: {X_val.shape[0]}')\n",
    "print(f'Number of testing samples: {X_test.shape[0]}')\n",
    "print(f'\\nNumber of features: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 9934\n",
      "Number of validation samples: 1104\n",
      "Number of testing samples: 2760\n",
      "\n",
      "Number of features: 1148\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print(f'Number of validation samples: {X_val.shape[0]}')\n",
    "print(f'Number of testing samples: {X_test.shape[0]}')\n",
    "print(f'\\nNumber of features: {X_train.shape[1]}')\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(Y_val, dtype=torch.float32)), batch_size=Y_val.shape[0], shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(Y_test, dtype=torch.float32)), batch_size=Y_test.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_size, hidden_size,dropout_prob=0, depth=1):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout_prob)\n",
    "    )\n",
    "    for i in range(depth):\n",
    "        model.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout_prob))\n",
    "\n",
    "    model.append(torch.nn.Linear(hidden_size, 1))\n",
    "    return torch.nn.Sequential(*model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hyperparameter combinations: 108\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_sizes =  [256, 512, 1024]\n",
    "nums_epochs = [200]\n",
    "depth = [3, 4, 5]\n",
    "batch= [8, 16, 32]\n",
    "learning_rate = [0.01, 0.001]\n",
    "step_size_lr_decay = [10, 20]\n",
    "momentum = [0.9]\n",
    "dropout_prob = 0.2\n",
    "patience = 10\n",
    "\n",
    "hyperparameters = itertools.product(hidden_sizes, depth, nums_epochs, batch, learning_rate, step_size_lr_decay, momentum)\n",
    "n_comb = len(hidden_sizes)*len(depth)*len(nums_epochs)*len(batch)*len(learning_rate)*len(step_size_lr_decay)*len(momentum)\n",
    "print (f'Number of hyperparameter combinations: {n_comb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate the model\n",
    "def test_model(model,criterion,test_loader, device):\n",
    "    model.eval()\n",
    "    y_pred = torch.tensor([]).to(device)\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "    test_loss = 0\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        Y_hat = model(X)\n",
    "        loss = criterion(Y_hat, Y.unsqueeze(1))\n",
    "        test_loss += loss.item()\n",
    "        y_pred = torch.cat((y_pred, Y_hat.squeeze()))\n",
    "        y_true = torch.cat((y_true, Y.detach()))\n",
    "    test_loss /= len(test_loader)\n",
    "    return test_loss, y_pred.detach().cpu().numpy(), y_true.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, writer, device, patience, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1000000\n",
    "    best_epoch = 0\n",
    "    early_stop_counter = 0\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_epoch = time.time()\n",
    "        train_loss = 0\n",
    "        for X, Y in train_loader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            Y_hat = model(X)\n",
    "            loss = criterion(Y_hat.squeeze(), Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        model.eval()\n",
    "        val_loss,y_pred,y_true = test_model(model,criterion,val_loader,device)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        scheduler.step(val_loss)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            break\n",
    "        \n",
    "        print('Epoch [{}/{}] - {:.2f} seconds - val_loss: {:.6f} - patience: {}'.format(epoch+1,\n",
    "              num_epochs, time.time() - start_epoch, val_loss, early_stop_counter), end='\\r')\n",
    "\n",
    "    print('\\nTraining ended after {:.2f} seconds - Best val_loss: {:.6f}'.format(time.time() - start, best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_epoch, best_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter combination 1/108\n",
      "current_iter: 1,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 31nds - val_loss: 0.005250 - patience: 9\n",
      "\n",
      "Training ended after 117.95 seconds - Best val_loss: 0.004856\n",
      "Best epoch: 22 - Best val_loss: 0.004855860490351915\n",
      "Testing model...\n",
      "Model MSE: 0.005006830673664808, Best MSE: 0.005006830673664808\n",
      "Hyperparameter combination 1/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 2/108\n",
      "current_iter: 2,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 31nds - val_loss: 0.005327 - patience: 9\n",
      "\n",
      "Training ended after 113.17 seconds - Best val_loss: 0.004940\n",
      "Best epoch: 22 - Best val_loss: 0.004940300714224577\n",
      "Testing model...\n",
      "Model MSE: 0.005045547615736723, Best MSE: 0.005006830673664808\n",
      "Hyperparameter combination 2/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 3/108\n",
      "current_iter: 3,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 63nds - val_loss: 0.005211 - patience: 9\n",
      "\n",
      "Training ended after 291.23 seconds - Best val_loss: 0.005156\n",
      "Best epoch: 54 - Best val_loss: 0.005155898164957762\n",
      "Testing model...\n",
      "Model MSE: 0.004866738338023424, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 3/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 4/108\n",
      "current_iter: 4,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 48nds - val_loss: 0.005388 - patience: 9\n",
      "\n",
      "Training ended after 234.38 seconds - Best val_loss: 0.005083\n",
      "Best epoch: 39 - Best val_loss: 0.0050831870175898075\n",
      "Testing model...\n",
      "Model MSE: 0.005183735396713018, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 4/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 5/108\n",
      "current_iter: 5,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 21nds - val_loss: 0.005368 - patience: 9\n",
      "\n",
      "Training ended after 48.60 seconds - Best val_loss: 0.004949\n",
      "Best epoch: 12 - Best val_loss: 0.004948625341057777\n",
      "Testing model...\n",
      "Model MSE: 0.005299319978803396, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 5/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 6/108\n",
      "current_iter: 6,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 32nds - val_loss: 0.005024 - patience: 9\n",
      "\n",
      "Training ended after 61.61 seconds - Best val_loss: 0.004945\n",
      "Best epoch: 23 - Best val_loss: 0.004944918677210808\n",
      "Testing model...\n",
      "Model MSE: 0.004878693725913763, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 6/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 7/108\n",
      "current_iter: 7,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 73nds - val_loss: 0.005541 - patience: 9\n",
      "\n",
      "Training ended after 138.46 seconds - Best val_loss: 0.005486\n",
      "Best epoch: 64 - Best val_loss: 0.005485691130161285\n",
      "Testing model...\n",
      "Model MSE: 0.005278137046843767, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 7/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 8/108\n",
      "current_iter: 8,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 75nds - val_loss: 0.005499 - patience: 9\n",
      "\n",
      "Training ended after 141.81 seconds - Best val_loss: 0.005261\n",
      "Best epoch: 66 - Best val_loss: 0.00526107382029295\n",
      "Testing model...\n",
      "Model MSE: 0.005265804007649422, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 8/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 9/108\n",
      "current_iter: 9,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 37nds - val_loss: 0.005182 - patience: 9\n",
      "\n",
      "Training ended after 40.18 seconds - Best val_loss: 0.004714\n",
      "Best epoch: 28 - Best val_loss: 0.004714235197752714\n",
      "Testing model...\n",
      "Model MSE: 0.0049598258920013905, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 9/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 10/108\n",
      "current_iter: 10,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 42nds - val_loss: 0.005523 - patience: 9\n",
      "\n",
      "Training ended after 45.38 seconds - Best val_loss: 0.004991\n",
      "Best epoch: 33 - Best val_loss: 0.004990751855075359\n",
      "Testing model...\n",
      "Model MSE: 0.005057458765804768, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 10/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 11/108\n",
      "current_iter: 11,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 153nds - val_loss: 0.005265 - patience: 9\n",
      "\n",
      "Training ended after 162.41 seconds - Best val_loss: 0.005210\n",
      "Best epoch: 144 - Best val_loss: 0.005209841299802065\n",
      "Testing model...\n",
      "Model MSE: 0.005084197968244553, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 11/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 12/108\n",
      "current_iter: 12,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 107nds - val_loss: 0.005625 - patience: 9\n",
      "\n",
      "Training ended after 114.71 seconds - Best val_loss: 0.005487\n",
      "Best epoch: 98 - Best val_loss: 0.005487243644893169\n",
      "Testing model...\n",
      "Model MSE: 0.005511907394975424, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 12/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 13/108\n",
      "current_iter: 13,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 38nds - val_loss: 0.005540 - patience: 9\n",
      "\n",
      "Training ended after 209.26 seconds - Best val_loss: 0.004794\n",
      "Best epoch: 29 - Best val_loss: 0.004794418346136808\n",
      "Testing model...\n",
      "Model MSE: 0.004927048459649086, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 13/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 14/108\n",
      "current_iter: 14,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 36nds - val_loss: 0.005654 - patience: 9\n",
      "\n",
      "Training ended after 200.05 seconds - Best val_loss: 0.005195\n",
      "Best epoch: 27 - Best val_loss: 0.0051954383961856365\n",
      "Testing model...\n",
      "Model MSE: 0.0053819166496396065, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 14/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 15/108\n",
      "current_iter: 15,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 76nds - val_loss: 0.005110 - patience: 9\n",
      "\n",
      "Training ended after 376.54 seconds - Best val_loss: 0.005006\n",
      "Best epoch: 67 - Best val_loss: 0.005005934275686741\n",
      "Testing model...\n",
      "Model MSE: 0.005064189899712801, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 15/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 16/108\n",
      "current_iter: 16,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 63nds - val_loss: 0.005339 - patience: 9\n",
      "\n",
      "Training ended after 325.04 seconds - Best val_loss: 0.005210\n",
      "Best epoch: 54 - Best val_loss: 0.005209972616285086\n",
      "Testing model...\n",
      "Model MSE: 0.00529856514185667, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 16/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 17/108\n",
      "current_iter: 17,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 40nds - val_loss: 0.006054 - patience: 9\n",
      "\n",
      "Training ended after 114.63 seconds - Best val_loss: 0.004766\n",
      "Best epoch: 31 - Best val_loss: 0.004766433499753475\n",
      "Testing model...\n",
      "Model MSE: 0.004932311829179525, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 17/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 18/108\n",
      "current_iter: 18,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 33nds - val_loss: 0.006560 - patience: 9\n",
      "\n",
      "Training ended after 96.89 seconds - Best val_loss: 0.005218\n",
      "Best epoch: 24 - Best val_loss: 0.005217898637056351\n",
      "Testing model...\n",
      "Model MSE: 0.005391230806708336, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 18/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 19/108\n",
      "current_iter: 19,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 123nds - val_loss: 0.005231 - patience: 9\n",
      "\n",
      "Training ended after 348.49 seconds - Best val_loss: 0.005207\n",
      "Best epoch: 114 - Best val_loss: 0.005207214038819075\n",
      "Testing model...\n",
      "Model MSE: 0.0051196604035794735, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 19/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 20/108\n",
      "current_iter: 20,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 108nds - val_loss: 0.005241 - patience: 9\n",
      "\n",
      "Training ended after 308.95 seconds - Best val_loss: 0.005207\n",
      "Best epoch: 99 - Best val_loss: 0.005207103211432695\n",
      "Testing model...\n",
      "Model MSE: 0.005190542433410883, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 20/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 21/108\n",
      "current_iter: 21,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 51nds - val_loss: 0.006161 - patience: 9\n",
      "\n",
      "Training ended after 67.61 seconds - Best val_loss: 0.005175\n",
      "Best epoch: 42 - Best val_loss: 0.005175070371478796\n",
      "Testing model...\n",
      "Model MSE: 0.004974201787263155, Best MSE: 0.004866738338023424\n",
      "Hyperparameter combination 21/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 22/108\n",
      "current_iter: 22,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 51nds - val_loss: 0.004830 - patience: 9\n",
      "\n",
      "Training ended after 60.47 seconds - Best val_loss: 0.004758\n",
      "Best epoch: 42 - Best val_loss: 0.004757702350616455\n",
      "Testing model...\n",
      "Model MSE: 0.004810195416212082, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 22/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 23/108\n",
      "current_iter: 23,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 92nds - val_loss: 0.006036 - patience: 9\n",
      "\n",
      "Training ended after 109.08 seconds - Best val_loss: 0.005910\n",
      "Best epoch: 83 - Best val_loss: 0.005909542553126812\n",
      "Testing model...\n",
      "Model MSE: 0.005873550195246935, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 23/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 24/108\n",
      "current_iter: 24,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 106nds - val_loss: 0.005691 - patience: 9\n",
      "\n",
      "Training ended after 124.45 seconds - Best val_loss: 0.005577\n",
      "Best epoch: 97 - Best val_loss: 0.005577079486101866\n",
      "Testing model...\n",
      "Model MSE: 0.0056078070774674416, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 24/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 25/108\n",
      "current_iter: 25,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 27nds - val_loss: 0.005815 - patience: 9\n",
      "\n",
      "Training ended after 126.60 seconds - Best val_loss: 0.005532\n",
      "Best epoch: 18 - Best val_loss: 0.005531503818929195\n",
      "Testing model...\n",
      "Model MSE: 0.005597366485744715, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 25/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 26/108\n",
      "current_iter: 26,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 30nds - val_loss: 0.006578 - patience: 9\n",
      "\n",
      "Training ended after 141.61 seconds - Best val_loss: 0.004830\n",
      "Best epoch: 21 - Best val_loss: 0.004829606506973505\n",
      "Testing model...\n",
      "Model MSE: 0.005024254322052002, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 26/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 27/108\n",
      "current_iter: 27,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 97nds - val_loss: 0.005350 - patience: 9\n",
      "\n",
      "Training ended after 428.51 seconds - Best val_loss: 0.005338\n",
      "Best epoch: 88 - Best val_loss: 0.005337578244507313\n",
      "Testing model...\n",
      "Model MSE: 0.005239684600383043, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 27/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 28/108\n",
      "current_iter: 28,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 65nds - val_loss: 0.005195 - patience: 9\n",
      "\n",
      "Training ended after 288.06 seconds - Best val_loss: 0.005162\n",
      "Best epoch: 56 - Best val_loss: 0.005161625798791647\n",
      "Testing model...\n",
      "Model MSE: 0.005236332770437002, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 28/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 29/108\n",
      "current_iter: 29,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 42nds - val_loss: 0.006432 - patience: 9\n",
      "\n",
      "Training ended after 102.01 seconds - Best val_loss: 0.005050\n",
      "Best epoch: 33 - Best val_loss: 0.0050504207611083984\n",
      "Testing model...\n",
      "Model MSE: 0.004966262262314558, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 29/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 30/108\n",
      "current_iter: 30,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 25nds - val_loss: 0.010532 - patience: 9\n",
      "\n",
      "Training ended after 78.78 seconds - Best val_loss: 0.005838\n",
      "Best epoch: 16 - Best val_loss: 0.005838100798428059\n",
      "Testing model...\n",
      "Model MSE: 0.00587865523993969, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 30/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 31/108\n",
      "current_iter: 31,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 87nds - val_loss: 0.005795 - patience: 9\n",
      "\n",
      "Training ended after 262.33 seconds - Best val_loss: 0.005711\n",
      "Best epoch: 78 - Best val_loss: 0.00571070471778512\n",
      "Testing model...\n",
      "Model MSE: 0.005452487617731094, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 31/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 32/108\n",
      "current_iter: 32,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 106nds - val_loss: 0.005232 - patience: 9\n",
      "\n",
      "Training ended after 320.00 seconds - Best val_loss: 0.005135\n",
      "Best epoch: 97 - Best val_loss: 0.005135326646268368\n",
      "Testing model...\n",
      "Model MSE: 0.0053711337968707085, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 32/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 33/108\n",
      "current_iter: 33,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 27nds - val_loss: 0.007305 - patience: 9\n",
      "\n",
      "Training ended after 45.87 seconds - Best val_loss: 0.006356\n",
      "Best epoch: 18 - Best val_loss: 0.006355579476803541\n",
      "Testing model...\n",
      "Model MSE: 0.0063569736666977406, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 33/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 34/108\n",
      "current_iter: 34,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 34nds - val_loss: 0.005242 - patience: 9\n",
      "\n",
      "Training ended after 57.46 seconds - Best val_loss: 0.005035\n",
      "Best epoch: 25 - Best val_loss: 0.005035175941884518\n",
      "Testing model...\n",
      "Model MSE: 0.005120007786899805, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 34/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 35/108\n",
      "current_iter: 35,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 117nds - val_loss: 0.006059 - patience: 9\n",
      "\n",
      "Training ended after 194.11 seconds - Best val_loss: 0.005850\n",
      "Best epoch: 108 - Best val_loss: 0.005849597044289112\n",
      "Testing model...\n",
      "Model MSE: 0.005906220059841871, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 35/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 36/108\n",
      "current_iter: 36,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 117nds - val_loss: 0.005813 - patience: 9\n",
      "\n",
      "Training ended after 193.51 seconds - Best val_loss: 0.005678\n",
      "Best epoch: 108 - Best val_loss: 0.005677895154803991\n",
      "Testing model...\n",
      "Model MSE: 0.005853697191923857, Best MSE: 0.004810195416212082\n",
      "Hyperparameter combination 36/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 37/108\n",
      "current_iter: 37,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 35nds - val_loss: 0.005053 - patience: 9\n",
      "\n",
      "Training ended after 145.09 seconds - Best val_loss: 0.004531\n",
      "Best epoch: 26 - Best val_loss: 0.00453059421852231\n",
      "Testing model...\n",
      "Model MSE: 0.004751136992126703, Best MSE: 0.004751136992126703\n",
      "Hyperparameter combination 37/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 38/108\n",
      "current_iter: 38,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 41nds - val_loss: 0.004761 - patience: 9\n",
      "\n",
      "Training ended after 170.40 seconds - Best val_loss: 0.004452\n",
      "Best epoch: 32 - Best val_loss: 0.0044518690556287766\n",
      "Testing model...\n",
      "Model MSE: 0.004727315157651901, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 38/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 39/108\n",
      "current_iter: 39,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 68nds - val_loss: 0.005037 - patience: 9\n",
      "\n",
      "Training ended after 280.05 seconds - Best val_loss: 0.004771\n",
      "Best epoch: 59 - Best val_loss: 0.004771268926560879\n",
      "Testing model...\n",
      "Model MSE: 0.0047944532707333565, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 39/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 40/108\n",
      "current_iter: 40,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 105nds - val_loss: 0.004891 - patience: 9\n",
      "\n",
      "Training ended after 431.64 seconds - Best val_loss: 0.004723\n",
      "Best epoch: 96 - Best val_loss: 0.0047226231545209885\n",
      "Testing model...\n",
      "Model MSE: 0.004737452138215303, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 40/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 41/108\n",
      "current_iter: 41,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 33nds - val_loss: 0.004816 - patience: 9\n",
      "\n",
      "Training ended after 73.54 seconds - Best val_loss: 0.004711\n",
      "Best epoch: 24 - Best val_loss: 0.004711107816547155\n",
      "Testing model...\n",
      "Model MSE: 0.004838420078158379, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 41/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 42/108\n",
      "current_iter: 42,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 41nds - val_loss: 0.005041 - patience: 9\n",
      "\n",
      "Training ended after 91.19 seconds - Best val_loss: 0.004630\n",
      "Best epoch: 32 - Best val_loss: 0.004629719071090221\n",
      "Testing model...\n",
      "Model MSE: 0.0047831241972744465, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 42/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 43/108\n",
      "current_iter: 43,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 78nds - val_loss: 0.005113 - patience: 9\n",
      "\n",
      "Training ended after 170.99 seconds - Best val_loss: 0.005077\n",
      "Best epoch: 69 - Best val_loss: 0.005076886620372534\n",
      "Testing model...\n",
      "Model MSE: 0.005026204977184534, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 43/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 44/108\n",
      "current_iter: 44,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 128nds - val_loss: 0.004858 - patience: 9\n",
      "\n",
      "Training ended after 280.07 seconds - Best val_loss: 0.004727\n",
      "Best epoch: 119 - Best val_loss: 0.004726610612124205\n",
      "Testing model...\n",
      "Model MSE: 0.004845551680773497, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 44/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 45/108\n",
      "current_iter: 45,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 26nds - val_loss: 0.005099 - patience: 9\n",
      "\n",
      "Training ended after 32.79 seconds - Best val_loss: 0.004756\n",
      "Best epoch: 17 - Best val_loss: 0.004756296519190073\n",
      "Testing model...\n",
      "Model MSE: 0.005051759537309408, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 45/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 46/108\n",
      "current_iter: 46,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 50nds - val_loss: 0.004780 - patience: 9\n",
      "\n",
      "Training ended after 61.25 seconds - Best val_loss: 0.004650\n",
      "Best epoch: 41 - Best val_loss: 0.004650165792554617\n",
      "Testing model...\n",
      "Model MSE: 0.004960247781127691, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 46/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 47/108\n",
      "current_iter: 47,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 104nds - val_loss: 0.005747 - patience: 9\n",
      "\n",
      "Training ended after 126.49 seconds - Best val_loss: 0.005562\n",
      "Best epoch: 95 - Best val_loss: 0.005561862140893936\n",
      "Testing model...\n",
      "Model MSE: 0.005488026887178421, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 47/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 48/108\n",
      "current_iter: 48,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 127nds - val_loss: 0.005249 - patience: 9\n",
      "\n",
      "Training ended after 155.46 seconds - Best val_loss: 0.005236\n",
      "Best epoch: 118 - Best val_loss: 0.005235685966908932\n",
      "Testing model...\n",
      "Model MSE: 0.005337856709957123, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 48/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 49/108\n",
      "current_iter: 49,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 35nds - val_loss: 0.004751 - patience: 9\n",
      "\n",
      "Training ended after 173.17 seconds - Best val_loss: 0.004517\n",
      "Best epoch: 26 - Best val_loss: 0.004517132416367531\n",
      "Testing model...\n",
      "Model MSE: 0.0047392030246555805, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 49/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 50/108\n",
      "current_iter: 50,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 41nds - val_loss: 0.004647 - patience: 9\n",
      "\n",
      "Training ended after 219.50 seconds - Best val_loss: 0.004512\n",
      "Best epoch: 32 - Best val_loss: 0.0045119584538042545\n",
      "Testing model...\n",
      "Model MSE: 0.004737206734716892, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 50/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 51/108\n",
      "current_iter: 51,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 79nds - val_loss: 0.005025 - patience: 9\n",
      "\n",
      "Training ended after 408.99 seconds - Best val_loss: 0.004910\n",
      "Best epoch: 70 - Best val_loss: 0.004910437390208244\n",
      "Testing model...\n",
      "Model MSE: 0.004888676572591066, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 51/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 52/108\n",
      "current_iter: 52,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 37nds - val_loss: 0.005492 - patience: 9\n",
      "\n",
      "Training ended after 218.71 seconds - Best val_loss: 0.005459\n",
      "Best epoch: 28 - Best val_loss: 0.005459416192024946\n",
      "Testing model...\n",
      "Model MSE: 0.005485589616000652, Best MSE: 0.004727315157651901\n",
      "Hyperparameter combination 52/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 53/108\n",
      "current_iter: 53,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 43nds - val_loss: 0.004771 - patience: 9\n",
      "\n",
      "Training ended after 123.24 seconds - Best val_loss: 0.004616\n",
      "Best epoch: 34 - Best val_loss: 0.0046163396909832954\n",
      "Testing model...\n",
      "Model MSE: 0.004690917674452066, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 53/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 54/108\n",
      "current_iter: 54,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 28nds - val_loss: 0.005022 - patience: 9\n",
      "\n",
      "Training ended after 71.94 seconds - Best val_loss: 0.004876\n",
      "Best epoch: 19 - Best val_loss: 0.004875697195529938\n",
      "Testing model...\n",
      "Model MSE: 0.005069154314696789, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 54/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 55/108\n",
      "current_iter: 55,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 78nds - val_loss: 0.005577 - patience: 9\n",
      "\n",
      "Training ended after 194.22 seconds - Best val_loss: 0.005204\n",
      "Best epoch: 69 - Best val_loss: 0.005204206798225641\n",
      "Testing model...\n",
      "Model MSE: 0.00525878369808197, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 55/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 56/108\n",
      "current_iter: 56,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 65nds - val_loss: 0.005307 - patience: 9\n",
      "\n",
      "Training ended after 207.73 seconds - Best val_loss: 0.005099\n",
      "Best epoch: 56 - Best val_loss: 0.005099101457744837\n",
      "Testing model...\n",
      "Model MSE: 0.005445726215839386, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 56/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 57/108\n",
      "current_iter: 57,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 50nds - val_loss: 0.005193 - patience: 9\n",
      "\n",
      "Training ended after 85.20 seconds - Best val_loss: 0.004741\n",
      "Best epoch: 41 - Best val_loss: 0.004741155542433262\n",
      "Testing model...\n",
      "Model MSE: 0.0048016756772994995, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 57/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 58/108\n",
      "current_iter: 58,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 54nds - val_loss: 0.004957 - patience: 9\n",
      "\n",
      "Training ended after 88.96 seconds - Best val_loss: 0.004753\n",
      "Best epoch: 45 - Best val_loss: 0.004753229208290577\n",
      "Testing model...\n",
      "Model MSE: 0.004719818010926247, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 58/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 59/108\n",
      "current_iter: 59,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 82nds - val_loss: 0.006043 - patience: 9\n",
      "\n",
      "Training ended after 142.45 seconds - Best val_loss: 0.005691\n",
      "Best epoch: 73 - Best val_loss: 0.0056911190040409565\n",
      "Testing model...\n",
      "Model MSE: 0.0058653331361711025, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 59/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 60/108\n",
      "current_iter: 60,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 67nds - val_loss: 0.006629 - patience: 9\n",
      "\n",
      "Training ended after 112.93 seconds - Best val_loss: 0.006297\n",
      "Best epoch: 58 - Best val_loss: 0.006297435611486435\n",
      "Testing model...\n",
      "Model MSE: 0.00614857766777277, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 60/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 61/108\n",
      "current_iter: 61,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 33nds - val_loss: 0.006122 - patience: 9\n",
      "\n",
      "Training ended after 221.89 seconds - Best val_loss: 0.004740\n",
      "Best epoch: 24 - Best val_loss: 0.004740062169730663\n",
      "Testing model...\n",
      "Model MSE: 0.005076269153505564, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 61/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 62/108\n",
      "current_iter: 62,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 21nds - val_loss: 0.006538 - patience: 9\n",
      "\n",
      "Training ended after 141.41 seconds - Best val_loss: 0.004804\n",
      "Best epoch: 12 - Best val_loss: 0.004803942050784826\n",
      "Testing model...\n",
      "Model MSE: 0.004834969528019428, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 62/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 63/108\n",
      "current_iter: 63,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 50nds - val_loss: 0.005148 - patience: 9\n",
      "\n",
      "Training ended after 301.83 seconds - Best val_loss: 0.005104\n",
      "Best epoch: 41 - Best val_loss: 0.00510407006368041\n",
      "Testing model...\n",
      "Model MSE: 0.005201278254389763, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 63/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 64/108\n",
      "current_iter: 64,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 67nds - val_loss: 0.004946 - patience: 9\n",
      "\n",
      "Training ended after 329.48 seconds - Best val_loss: 0.004823\n",
      "Best epoch: 58 - Best val_loss: 0.004823080264031887\n",
      "Testing model...\n",
      "Model MSE: 0.004956494551151991, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 64/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 65/108\n",
      "current_iter: 65,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 38nds - val_loss: 0.005687 - patience: 9\n",
      "\n",
      "Training ended after 119.03 seconds - Best val_loss: 0.004962\n",
      "Best epoch: 29 - Best val_loss: 0.004962220788002014\n",
      "Testing model...\n",
      "Model MSE: 0.0049308305606245995, Best MSE: 0.004690917674452066\n",
      "Hyperparameter combination 65/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 66/108\n",
      "current_iter: 66,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 55nds - val_loss: 0.005242 - patience: 9\n",
      "\n",
      "Training ended after 165.09 seconds - Best val_loss: 0.004566\n",
      "Best epoch: 46 - Best val_loss: 0.004565508104860783\n",
      "Testing model...\n",
      "Model MSE: 0.004672421608120203, Best MSE: 0.004672421608120203\n",
      "Hyperparameter combination 66/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 67/108\n",
      "current_iter: 67,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 136nds - val_loss: 0.004965 - patience: 9\n",
      "\n",
      "Training ended after 403.31 seconds - Best val_loss: 0.004873\n",
      "Best epoch: 127 - Best val_loss: 0.004873155616223812\n",
      "Testing model...\n",
      "Model MSE: 0.004988990258425474, Best MSE: 0.004672421608120203\n",
      "Hyperparameter combination 67/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 68/108\n",
      "current_iter: 68,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 86nds - val_loss: 0.005619 - patience: 9\n",
      "\n",
      "Training ended after 268.74 seconds - Best val_loss: 0.005224\n",
      "Best epoch: 77 - Best val_loss: 0.0052238875068724155\n",
      "Testing model...\n",
      "Model MSE: 0.0052609615959227085, Best MSE: 0.004672421608120203\n",
      "Hyperparameter combination 68/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 69/108\n",
      "current_iter: 69,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 43nds - val_loss: 0.005675 - patience: 9\n",
      "\n",
      "Training ended after 73.20 seconds - Best val_loss: 0.005048\n",
      "Best epoch: 34 - Best val_loss: 0.005047763232141733\n",
      "Testing model...\n",
      "Model MSE: 0.005065962206572294, Best MSE: 0.004672421608120203\n",
      "Hyperparameter combination 69/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 70/108\n",
      "current_iter: 70,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 46nds - val_loss: 0.006648 - patience: 9\n",
      "\n",
      "Training ended after 79.45 seconds - Best val_loss: 0.005139\n",
      "Best epoch: 37 - Best val_loss: 0.005138890817761421\n",
      "Testing model...\n",
      "Model MSE: 0.0051419478841125965, Best MSE: 0.004672421608120203\n",
      "Hyperparameter combination 70/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 71/108\n",
      "current_iter: 71,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 92nds - val_loss: 0.006528 - patience: 9\n",
      "\n",
      "Training ended after 146.57 seconds - Best val_loss: 0.006071\n",
      "Best epoch: 83 - Best val_loss: 0.006070699077099562\n",
      "Testing model...\n",
      "Model MSE: 0.006006753072142601, Best MSE: 0.004672421608120203\n",
      "Hyperparameter combination 71/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 72/108\n",
      "current_iter: 72,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 112nds - val_loss: 0.005873 - patience: 9\n",
      "\n",
      "Training ended after 180.57 seconds - Best val_loss: 0.005658\n",
      "Best epoch: 103 - Best val_loss: 0.005657920613884926\n",
      "Testing model...\n",
      "Model MSE: 0.005676155909895897, Best MSE: 0.004672421608120203\n",
      "Hyperparameter combination 72/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 73/108\n",
      "current_iter: 73,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 40nds - val_loss: 0.005334 - patience: 9\n",
      "\n",
      "Training ended after 218.15 seconds - Best val_loss: 0.004458\n",
      "Best epoch: 31 - Best val_loss: 0.004458052106201649\n",
      "Testing model...\n",
      "Model MSE: 0.004562627524137497, Best MSE: 0.004562627524137497\n",
      "Hyperparameter combination 73/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 74/108\n",
      "current_iter: 74,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 37nds - val_loss: 0.004626 - patience: 9\n",
      "\n",
      "Training ended after 203.28 seconds - Best val_loss: 0.004399\n",
      "Best epoch: 28 - Best val_loss: 0.004399241879582405\n",
      "Testing model...\n",
      "Model MSE: 0.004600057378411293, Best MSE: 0.004562627524137497\n",
      "Hyperparameter combination 74/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 75/108\n",
      "current_iter: 75,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 61nds - val_loss: 0.004721 - patience: 9\n",
      "\n",
      "Training ended after 332.37 seconds - Best val_loss: 0.004660\n",
      "Best epoch: 52 - Best val_loss: 0.004660080187022686\n",
      "Testing model...\n",
      "Model MSE: 0.004836573265492916, Best MSE: 0.004562627524137497\n",
      "Hyperparameter combination 75/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 76/108\n",
      "current_iter: 76,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 30nds - val_loss: 0.005398 - patience: 9\n",
      "\n",
      "Training ended after 164.55 seconds - Best val_loss: 0.005043\n",
      "Best epoch: 21 - Best val_loss: 0.005043199751526117\n",
      "Testing model...\n",
      "Model MSE: 0.005286223720759153, Best MSE: 0.004562627524137497\n",
      "Hyperparameter combination 76/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 77/108\n",
      "current_iter: 77,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 32nds - val_loss: 0.004639 - patience: 9\n",
      "\n",
      "Training ended after 88.97 seconds - Best val_loss: 0.004614\n",
      "Best epoch: 23 - Best val_loss: 0.004613600671291351\n",
      "Testing model...\n",
      "Model MSE: 0.004701345693320036, Best MSE: 0.004562627524137497\n",
      "Hyperparameter combination 77/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 78/108\n",
      "current_iter: 78,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 43nds - val_loss: 0.004732 - patience: 9\n",
      "\n",
      "Training ended after 117.48 seconds - Best val_loss: 0.004555\n",
      "Best epoch: 34 - Best val_loss: 0.0045547704212367535\n",
      "Testing model...\n",
      "Model MSE: 0.0045013208873569965, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 78/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 79/108\n",
      "current_iter: 79,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 57nds - val_loss: 0.005297 - patience: 9\n",
      "\n",
      "Training ended after 159.52 seconds - Best val_loss: 0.005201\n",
      "Best epoch: 48 - Best val_loss: 0.005201071035116911\n",
      "Testing model...\n",
      "Model MSE: 0.005190604366362095, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 79/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 80/108\n",
      "current_iter: 80,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 65nds - val_loss: 0.005207 - patience: 9\n",
      "\n",
      "Training ended after 183.55 seconds - Best val_loss: 0.004792\n",
      "Best epoch: 56 - Best val_loss: 0.004791606683284044\n",
      "Testing model...\n",
      "Model MSE: 0.004966856446117163, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 80/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 81/108\n",
      "current_iter: 81,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 47nds - val_loss: 0.004843 - patience: 9\n",
      "\n",
      "Training ended after 73.33 seconds - Best val_loss: 0.004600\n",
      "Best epoch: 38 - Best val_loss: 0.0046000368893146515\n",
      "Testing model...\n",
      "Model MSE: 0.004655591677874327, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 81/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 82/108\n",
      "current_iter: 82,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 32nds - val_loss: 0.004884 - patience: 9\n",
      "\n",
      "Training ended after 50.53 seconds - Best val_loss: 0.004699\n",
      "Best epoch: 23 - Best val_loss: 0.0046989284455776215\n",
      "Testing model...\n",
      "Model MSE: 0.004736867267638445, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 82/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 83/108\n",
      "current_iter: 83,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 97nds - val_loss: 0.005490 - patience: 9\n",
      "\n",
      "Training ended after 149.09 seconds - Best val_loss: 0.005135\n",
      "Best epoch: 88 - Best val_loss: 0.005135283339768648\n",
      "Testing model...\n",
      "Model MSE: 0.005196588579565287, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 83/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 84/108\n",
      "current_iter: 84,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 115nds - val_loss: 0.005173 - patience: 9\n",
      "\n",
      "Training ended after 177.76 seconds - Best val_loss: 0.005064\n",
      "Best epoch: 106 - Best val_loss: 0.005064466968178749\n",
      "Testing model...\n",
      "Model MSE: 0.005210877861827612, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 84/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 85/108\n",
      "current_iter: 85,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 23nds - val_loss: 0.005124 - patience: 9\n",
      "\n",
      "Training ended after 146.29 seconds - Best val_loss: 0.004470\n",
      "Best epoch: 14 - Best val_loss: 0.004470457322895527\n",
      "Testing model...\n",
      "Model MSE: 0.0045855166390538216, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 85/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 86/108\n",
      "current_iter: 86,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 44nds - val_loss: 0.004727 - patience: 9\n",
      "\n",
      "Training ended after 282.01 seconds - Best val_loss: 0.004332\n",
      "Best epoch: 35 - Best val_loss: 0.0043318006210029125\n",
      "Testing model...\n",
      "Model MSE: 0.004545208532363176, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 86/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 87/108\n",
      "current_iter: 87,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 43nds - val_loss: 0.005311 - patience: 9\n",
      "\n",
      "Training ended after 280.39 seconds - Best val_loss: 0.005096\n",
      "Best epoch: 34 - Best val_loss: 0.005096444394439459\n",
      "Testing model...\n",
      "Model MSE: 0.005167108494788408, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 87/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 88/108\n",
      "current_iter: 88,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 91nds - val_loss: 0.004821 - patience: 9\n",
      "\n",
      "Training ended after 589.25 seconds - Best val_loss: 0.004605\n",
      "Best epoch: 82 - Best val_loss: 0.004605488386005163\n",
      "Testing model...\n",
      "Model MSE: 0.00468195416033268, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 88/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 89/108\n",
      "current_iter: 89,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 41nds - val_loss: 0.004680 - patience: 9\n",
      "\n",
      "Training ended after 132.91 seconds - Best val_loss: 0.004466\n",
      "Best epoch: 32 - Best val_loss: 0.004466249141842127\n",
      "Testing model...\n",
      "Model MSE: 0.0045990110374987125, Best MSE: 0.0045013208873569965\n",
      "Hyperparameter combination 89/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 90/108\n",
      "current_iter: 90,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 37nds - val_loss: 0.004672 - patience: 9\n",
      "\n",
      "Training ended after 119.39 seconds - Best val_loss: 0.004521\n",
      "Best epoch: 28 - Best val_loss: 0.004520629532635212\n",
      "Testing model...\n",
      "Model MSE: 0.0044402782805264, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 90/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 91/108\n",
      "current_iter: 91,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 81nds - val_loss: 0.005133 - patience: 9\n",
      "\n",
      "Training ended after 260.14 seconds - Best val_loss: 0.004962\n",
      "Best epoch: 72 - Best val_loss: 0.004961609840393066\n",
      "Testing model...\n",
      "Model MSE: 0.005056910216808319, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 91/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 92/108\n",
      "current_iter: 92,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 87nds - val_loss: 0.004918 - patience: 9\n",
      "\n",
      "Training ended after 287.33 seconds - Best val_loss: 0.004869\n",
      "Best epoch: 78 - Best val_loss: 0.00486901868134737\n",
      "Testing model...\n",
      "Model MSE: 0.004866627044975758, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 92/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 93/108\n",
      "current_iter: 93,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 64nds - val_loss: 0.004690 - patience: 9\n",
      "\n",
      "Training ended after 111.84 seconds - Best val_loss: 0.004672\n",
      "Best epoch: 55 - Best val_loss: 0.004672374576330185\n",
      "Testing model...\n",
      "Model MSE: 0.004613383673131466, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 93/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 94/108\n",
      "current_iter: 94,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 99nds - val_loss: 0.004685 - patience: 9\n",
      "\n",
      "Training ended after 171.71 seconds - Best val_loss: 0.004358\n",
      "Best epoch: 90 - Best val_loss: 0.004357689525932074\n",
      "Testing model...\n",
      "Model MSE: 0.004594455938786268, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 94/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 95/108\n",
      "current_iter: 95,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 135nds - val_loss: 0.005230 - patience: 9\n",
      "\n",
      "Training ended after 232.95 seconds - Best val_loss: 0.005060\n",
      "Best epoch: 126 - Best val_loss: 0.005059557501226664\n",
      "Testing model...\n",
      "Model MSE: 0.0052535030990839005, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 95/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 96/108\n",
      "current_iter: 96,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 100nds - val_loss: 0.005485 - patience: 9\n",
      "\n",
      "Training ended after 174.41 seconds - Best val_loss: 0.005281\n",
      "Best epoch: 91 - Best val_loss: 0.005280983634293079\n",
      "Testing model...\n",
      "Model MSE: 0.005416851956397295, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 96/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 97/108\n",
      "current_iter: 97,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 43nds - val_loss: 0.004538 - patience: 9\n",
      "\n",
      "Training ended after 301.21 seconds - Best val_loss: 0.004303\n",
      "Best epoch: 34 - Best val_loss: 0.004302830435335636\n",
      "Testing model...\n",
      "Model MSE: 0.004622627981007099, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 97/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 98/108\n",
      "current_iter: 98,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 27nds - val_loss: 0.004645 - patience: 9\n",
      "\n",
      "Training ended after 190.81 seconds - Best val_loss: 0.004637\n",
      "Best epoch: 18 - Best val_loss: 0.0046370006166398525\n",
      "Testing model...\n",
      "Model MSE: 0.004750845022499561, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 98/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 99/108\n",
      "current_iter: 99,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 61nds - val_loss: 0.005075 - patience: 9\n",
      "\n",
      "Training ended after 431.38 seconds - Best val_loss: 0.004887\n",
      "Best epoch: 52 - Best val_loss: 0.0048873405903577805\n",
      "Testing model...\n",
      "Model MSE: 0.004993229638785124, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 99/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 100/108\n",
      "current_iter: 100,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 34nds - val_loss: 0.005636 - patience: 9\n",
      "\n",
      "Training ended after 257.40 seconds - Best val_loss: 0.005329\n",
      "Best epoch: 25 - Best val_loss: 0.005329295061528683\n",
      "Testing model...\n",
      "Model MSE: 0.005363915115594864, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 100/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 101/108\n",
      "current_iter: 101,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 39nds - val_loss: 0.006230 - patience: 9\n",
      "\n",
      "Training ended after 142.71 seconds - Best val_loss: 0.004678\n",
      "Best epoch: 30 - Best val_loss: 0.004678128752857447\n",
      "Testing model...\n",
      "Model MSE: 0.004627815447747707, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 101/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 102/108\n",
      "current_iter: 102,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 38nds - val_loss: 0.004677 - patience: 9\n",
      "\n",
      "Training ended after 137.82 seconds - Best val_loss: 0.004644\n",
      "Best epoch: 29 - Best val_loss: 0.004644440487027168\n",
      "Testing model...\n",
      "Model MSE: 0.004749036859720945, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 102/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 103/108\n",
      "current_iter: 103,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 59nds - val_loss: 0.005827 - patience: 9\n",
      "\n",
      "Training ended after 212.05 seconds - Best val_loss: 0.005531\n",
      "Best epoch: 50 - Best val_loss: 0.005530811846256256\n",
      "Testing model...\n",
      "Model MSE: 0.0056597585789859295, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 103/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 104/108\n",
      "current_iter: 104,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 60nds - val_loss: 0.005456 - patience: 9\n",
      "\n",
      "Training ended after 215.65 seconds - Best val_loss: 0.005280\n",
      "Best epoch: 51 - Best val_loss: 0.005279950797557831\n",
      "Testing model...\n",
      "Model MSE: 0.005353798624128103, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 104/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 105/108\n",
      "current_iter: 105,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 58nds - val_loss: 0.004643 - patience: 9\n",
      "\n",
      "Training ended after 113.20 seconds - Best val_loss: 0.004520\n",
      "Best epoch: 49 - Best val_loss: 0.004520399495959282\n",
      "Testing model...\n",
      "Model MSE: 0.004509252961724997, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 105/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 106/108\n",
      "current_iter: 106,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 45nds - val_loss: 0.004974 - patience: 9\n",
      "\n",
      "Training ended after 86.90 seconds - Best val_loss: 0.004761\n",
      "Best epoch: 36 - Best val_loss: 0.004760846961289644\n",
      "Testing model...\n",
      "Model MSE: 0.0046865735203027725, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 106/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 107/108\n",
      "current_iter: 107,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 94nds - val_loss: 0.005951 - patience: 9\n",
      "\n",
      "Training ended after 179.78 seconds - Best val_loss: 0.005712\n",
      "Best epoch: 85 - Best val_loss: 0.005712244659662247\n",
      "Testing model...\n",
      "Model MSE: 0.005554755683988333, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 107/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 108/108\n",
      "current_iter: 108,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 129nds - val_loss: 0.005213 - patience: 9\n",
      "\n",
      "Training ended after 245.16 seconds - Best val_loss: 0.005114\n",
      "Best epoch: 120 - Best val_loss: 0.005114195868372917\n",
      "Testing model...\n",
      "Model MSE: 0.005241731647402048, Best MSE: 0.0044402782805264\n",
      "Hyperparameter combination 108/108 finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grid search loop\n",
    "best_mse = float('inf')\n",
    "current_iter = 0\n",
    "for i, (hidden_size, depth, num_epochs, batch, lr, step_size, momentum) in enumerate(hyperparameters):\n",
    "    current_iter += 1\n",
    "    print(f'\\nHyperparameter combination {i+1}/{n_comb}')\n",
    "    print(f'current_iter: {current_iter},hidden_size: {hidden_size}, depth: {depth}, num_epochs: {num_epochs}, batch_size: {batch}, lr: {lr}, step_size: {step_size}, momentum: {momentum}')\n",
    "    writer = SummaryWriter(f'run/NoPCA/Dnn/hidden_size={hidden_size}, depth={depth}, num_epochs={num_epochs}, batch_size={batch}, lr={lr}, step_size={step_size}, momentum={momentum}')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32)), batch_size=batch, shuffle=True)\n",
    "    model = get_model(X_train.shape[1], hidden_size, dropout_prob, depth).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr,momentum=momentum)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=step_size,gamma=0.1)\n",
    "    model, best_epoch, best_loss = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, writer, device, patience, num_epochs)\n",
    "   \n",
    "    \n",
    "    print(f'Best epoch: {best_epoch+1} - Best val_loss: {best_loss}')\n",
    "    print(f'Testing model...')\n",
    "    test_loss,_,_ = test_model(model,criterion,test_loader, device)\n",
    "    writer.add_hparams({'hidden_size': hidden_size, 'depth': depth, 'batch': batch,'lr': lr, 'step_size': step_size, 'momentum': momentum}, {'hparam/mse': test_loss})\n",
    "    if test_loss < best_mse:\n",
    "        best_mse = test_loss\n",
    "        best_model = model\n",
    "        \n",
    "        history_loss = best_epoch\n",
    "        history_val_loss = best_loss\n",
    "\n",
    "        torch.save(model.state_dict(), 'best_model_nopca.pth')\n",
    "        # save config\n",
    "        with open('best_model_config_nopca.json', 'w') as f:\n",
    "            json.dump({'hidden_size': hidden_size, 'depth': depth, 'num_epochs': num_epochs, 'batch': batch,\n",
    "                       'lr': lr, 'step_size': step_size}, f)   \n",
    "\n",
    "    writer.flush()\n",
    "    print(f'Model MSE: {test_loss}, Best MSE: {best_mse}')\n",
    "    print(f'Hyperparameter combination {i+1}/{n_comb} finished\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model - MSE: 0.004884\n",
      "R2: 0.978349 - MSE: 0.004884\n"
     ]
    }
   ],
   "source": [
    "#best configuration with PCA\n",
    "criterion =  torch.nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "with open('best_model_config.json', 'r') as f:\n",
    "        best_model_config = json.load(f)\n",
    "\n",
    "best_model = get_model(X_train.shape[1], best_model_config['hidden_size'], dropout_prob, best_model_config['depth'])\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "# evaluate best model\n",
    "best_mse,y_pred,y_true= test_model(best_model, criterion, test_loader,device)   \n",
    "print(\"Best model - MSE: {:.6f}\".format(best_mse))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(\"R2: {:.6f} - MSE: {:.6f}\".format(r2, mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model No PCA - MSE: 0.004440\n",
      "R2: 0.980314 - MSE: 0.004440\n"
     ]
    }
   ],
   "source": [
    "#best configuration without PCA\n",
    "criterion =  torch.nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "with open('best_model_config_nopca.json', 'r') as f:\n",
    "        best_model_config = json.load(f)\n",
    "\n",
    "best_model = get_model(X_train.shape[1], best_model_config['hidden_size'], dropout_prob, best_model_config['depth'])\n",
    "best_model.load_state_dict(torch.load('best_model_nopca.pth'))\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "# evaluate best model\n",
    "best_mse,y_pred,y_true= test_model(best_model, criterion, test_loader,device)   \n",
    "print(\"Best model No PCA - MSE: {:.6f}\".format(best_mse))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(\"R2: {:.6f} - MSE: {:.6f}\".format(r2, mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
