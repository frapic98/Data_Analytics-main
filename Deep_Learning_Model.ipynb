{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, HalvingGridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def fix_random(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower\n",
    "fix_random(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# PyTorch Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2_normalization\n"
     ]
    }
   ],
   "source": [
    "columns_to_transform = ['year', 'rating_count']\n",
    "\n",
    "\n",
    "def transform(X):\n",
    "    X_norm2 = np.linalg.norm(X, ord=2)\n",
    "    X = X / X_norm2\n",
    "    return X\n",
    "\n",
    "def normalize(df, type):\n",
    "    print(type)\n",
    "    for column in columns_to_transform:\n",
    "        df[column] = transform(df[column])\n",
    "    return df\n",
    "df=normalize(df, 'L2_normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('rating', axis=1)\n",
    "Y = df['rating']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y_val = Y_val.to_numpy()\n",
    "Y_test = Y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_val = pca.transform(X_val)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 9934\n",
      "Number of validation samples: 1104\n",
      "Number of testing samples: 2760\n",
      "\n",
      "Number of features: 543\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print(f'Number of validation samples: {X_val.shape[0]}')\n",
    "print(f'Number of testing samples: {X_test.shape[0]}')\n",
    "print(f'\\nNumber of features: {X_train.shape[1]}')\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(Y_val, dtype=torch.float32)), batch_size=Y_val.shape[0], shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(Y_test, dtype=torch.float32)), batch_size=Y_test.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to get Deep Learning model with torch.nn\n",
    "def get_model(input_size, hidden_size,dropout_prob=0, depth=1):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(input_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout_prob)\n",
    "    )\n",
    "    for i in range(depth):\n",
    "        model.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "        model.append(torch.nn.ReLU())\n",
    "        model.append(torch.nn.Dropout(dropout_prob))\n",
    "\n",
    "    model.append(torch.nn.Linear(hidden_size, 1))\n",
    "    return torch.nn.Sequential(*model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hyperparameter combinations: 108\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "hidden_sizes =  [256, 512, 1024]\n",
    "nums_epochs = [200]\n",
    "depth = [3, 4, 5]\n",
    "batch= [8, 16, 32]\n",
    "learning_rate = [0.01, 0.001]\n",
    "step_size_lr_decay = [10, 20]\n",
    "momentum = [0.9]\n",
    "dropout_prob = 0.2\n",
    "patience = 10\n",
    "\n",
    "hyperparameters = itertools.product(hidden_sizes, depth, nums_epochs, batch, learning_rate, step_size_lr_decay, momentum)\n",
    "n_comb = len(hidden_sizes)*len(depth)*len(nums_epochs)*len(batch)*len(learning_rate)*len(step_size_lr_decay)*len(momentum)\n",
    "print (f'Number of hyperparameter combinations: {n_comb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model given by the function get_model() with hyperparameters defined above\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, writer, device, patience, num_epochs):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1000000\n",
    "    best_epoch = 0\n",
    "    early_stop_counter = 0\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_epoch = time.time()\n",
    "        train_loss = 0\n",
    "        for X, Y in train_loader:\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            Y_hat = model(X)\n",
    "            loss = criterion(Y_hat.squeeze(), Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        model.eval()\n",
    "        val_loss = test_model(model, val_loader, criterion, device)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        scheduler.step(val_loss)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            break\n",
    "        \n",
    "        print('Epoch [{}/{}] - {:.2f} seconds - val_loss: {:.6f} - patience: {}'.format(epoch+1,\n",
    "              num_epochs, time.time() - start_epoch, val_loss, early_stop_counter), end='\\r')\n",
    "\n",
    "    print('\\nTraining ended after {:.2f} seconds - Best val_loss: {:.6f}'.format(time.time() - start, best_loss))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_epoch, best_loss\n",
    "\n",
    "#write a function to evaluate the model\n",
    "def test_model(model,criterion,test_loader, device):\n",
    "    model.eval()\n",
    "    y_pred = torch.tensor([]).to(device)\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "    test_loss = 0\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        Y_hat = model(X)\n",
    "        loss = criterion(Y_hat, Y.unsqueeze(1))\n",
    "        test_loss += loss.item()\n",
    "        y_pred = torch.cat((y_pred, Y_hat.squeeze()))\n",
    "        y_true = torch.cat((y_true, Y.detach()))\n",
    "    test_loss /= len(test_loader)\n",
    "    return test_loss, y_pred.detach().cpu().numpy(), y_true.detach().cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter combination 1/108\n",
      "current_iter: 1,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 72nds - val_loss: 0.005355 - patience: 9\n",
      "\n",
      "Training ended after 237.69 seconds - Best val_loss: 0.005263\n",
      "Best epoch: 63 - Best val_loss: 0.0052634659223258495\n",
      "Testing model...\n",
      "Model MSE: 0.0052941362373530865, Best MSE: 0.0052941362373530865\n",
      "Hyperparameter combination 1/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 2/108\n",
      "current_iter: 2,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 40nds - val_loss: 0.005786 - patience: 9\n",
      "\n",
      "Training ended after 67.82 seconds - Best val_loss: 0.005160\n",
      "Best epoch: 31 - Best val_loss: 0.005159705877304077\n",
      "Testing model...\n",
      "Model MSE: 0.005288165528327227, Best MSE: 0.005288165528327227\n",
      "Hyperparameter combination 2/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 3/108\n",
      "current_iter: 3,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 28nds - val_loss: 0.005521 - patience: 9\n",
      "\n",
      "Training ended after 47.58 seconds - Best val_loss: 0.005017\n",
      "Best epoch: 19 - Best val_loss: 0.005016508977860212\n",
      "Testing model...\n",
      "Model MSE: 0.005232258699834347, Best MSE: 0.005232258699834347\n",
      "Hyperparameter combination 3/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 4/108\n",
      "current_iter: 4,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 134nds - val_loss: 0.005516 - patience: 9\n",
      "\n",
      "Training ended after 219.98 seconds - Best val_loss: 0.005455\n",
      "Best epoch: 125 - Best val_loss: 0.005454875063151121\n",
      "Testing model...\n",
      "Model MSE: 0.00530534703284502, Best MSE: 0.005232258699834347\n",
      "Hyperparameter combination 4/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 5/108\n",
      "current_iter: 5,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 96nds - val_loss: 0.005527 - patience: 9\n",
      "\n",
      "Training ended after 188.85 seconds - Best val_loss: 0.005424\n",
      "Best epoch: 87 - Best val_loss: 0.005423516500741243\n",
      "Testing model...\n",
      "Model MSE: 0.0054302760399878025, Best MSE: 0.005232258699834347\n",
      "Hyperparameter combination 5/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 6/108\n",
      "current_iter: 6,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 51nds - val_loss: 0.005292 - patience: 9\n",
      "\n",
      "Training ended after 47.35 seconds - Best val_loss: 0.005247\n",
      "Best epoch: 42 - Best val_loss: 0.005247215274721384\n",
      "Testing model...\n",
      "Model MSE: 0.005191391333937645, Best MSE: 0.005191391333937645\n",
      "Hyperparameter combination 6/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 7/108\n",
      "current_iter: 7,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 54nds - val_loss: 0.005575 - patience: 9\n",
      "\n",
      "Training ended after 44.63 seconds - Best val_loss: 0.005061\n",
      "Best epoch: 45 - Best val_loss: 0.00506132747977972\n",
      "Testing model...\n",
      "Model MSE: 0.005212116055190563, Best MSE: 0.005191391333937645\n",
      "Hyperparameter combination 7/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 8/108\n",
      "current_iter: 8,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Epoch [200/200] - 0.86 seconds - val_loss: 0.005461 - patience: 0\n",
      "Training ended after 171.17 seconds - Best val_loss: 0.005461\n",
      "Best epoch: 200 - Best val_loss: 0.005461324006319046\n",
      "Testing model...\n",
      "Model MSE: 0.005439785309135914, Best MSE: 0.005191391333937645\n",
      "Hyperparameter combination 8/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 9/108\n",
      "current_iter: 9,hidden_size: 256, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 192nds - val_loss: 0.005570 - patience: 9\n",
      "\n",
      "Training ended after 165.57 seconds - Best val_loss: 0.005536\n",
      "Best epoch: 183 - Best val_loss: 0.005535505712032318\n",
      "Testing model...\n",
      "Model MSE: 0.005403037648648024, Best MSE: 0.005191391333937645\n",
      "Hyperparameter combination 9/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 10/108\n",
      "current_iter: 10,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 37nds - val_loss: 0.005790 - patience: 9\n",
      "\n",
      "Training ended after 133.99 seconds - Best val_loss: 0.005282\n",
      "Best epoch: 28 - Best val_loss: 0.005282211117446423\n",
      "Testing model...\n",
      "Model MSE: 0.005332597065716982, Best MSE: 0.005191391333937645\n",
      "Hyperparameter combination 10/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 11/108\n",
      "current_iter: 11,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 26nds - val_loss: 0.006796 - patience: 9\n",
      "\n",
      "Training ended after 92.29 seconds - Best val_loss: 0.005171\n",
      "Best epoch: 17 - Best val_loss: 0.0051710475236177444\n",
      "Testing model...\n",
      "Model MSE: 0.005059551447629929, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 11/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 12/108\n",
      "current_iter: 12,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 62nds - val_loss: 0.005543 - patience: 9\n",
      "\n",
      "Training ended after 215.57 seconds - Best val_loss: 0.005464\n",
      "Best epoch: 53 - Best val_loss: 0.005464173387736082\n",
      "Testing model...\n",
      "Model MSE: 0.005401614587754011, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 12/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 13/108\n",
      "current_iter: 13,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 62nds - val_loss: 0.005389 - patience: 9\n",
      "\n",
      "Training ended after 214.30 seconds - Best val_loss: 0.005257\n",
      "Best epoch: 53 - Best val_loss: 0.005257158074527979\n",
      "Testing model...\n",
      "Model MSE: 0.005413897801190615, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 13/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 14/108\n",
      "current_iter: 14,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 46nds - val_loss: 0.005726 - patience: 9\n",
      "\n",
      "Training ended after 107.45 seconds - Best val_loss: 0.005255\n",
      "Best epoch: 37 - Best val_loss: 0.005255197174847126\n",
      "Testing model...\n",
      "Model MSE: 0.00548156863078475, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 14/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 15/108\n",
      "current_iter: 15,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 24nds - val_loss: 0.005947 - patience: 9\n",
      "\n",
      "Training ended after 57.75 seconds - Best val_loss: 0.005303\n",
      "Best epoch: 15 - Best val_loss: 0.005302871577441692\n",
      "Testing model...\n",
      "Model MSE: 0.005368751939386129, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 15/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 16/108\n",
      "current_iter: 16,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 114nds - val_loss: 0.005433 - patience: 9\n",
      "\n",
      "Training ended after 229.78 seconds - Best val_loss: 0.005383\n",
      "Best epoch: 105 - Best val_loss: 0.005382707808166742\n",
      "Testing model...\n",
      "Model MSE: 0.005439327098429203, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 16/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 17/108\n",
      "current_iter: 17,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 161nds - val_loss: 0.005239 - patience: 9\n",
      "\n",
      "Training ended after 370.10 seconds - Best val_loss: 0.005206\n",
      "Best epoch: 152 - Best val_loss: 0.00520592276006937\n",
      "Testing model...\n",
      "Model MSE: 0.005407695192843676, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 17/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 18/108\n",
      "current_iter: 18,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 26nds - val_loss: 0.005534 - patience: 9\n",
      "\n",
      "Training ended after 33.33 seconds - Best val_loss: 0.005506\n",
      "Best epoch: 17 - Best val_loss: 0.0055062235333025455\n",
      "Testing model...\n",
      "Model MSE: 0.005615646950900555, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 18/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 19/108\n",
      "current_iter: 19,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 53nds - val_loss: 0.005333 - patience: 9\n",
      "\n",
      "Training ended after 65.09 seconds - Best val_loss: 0.005234\n",
      "Best epoch: 44 - Best val_loss: 0.0052340151742100716\n",
      "Testing model...\n",
      "Model MSE: 0.005374927539378405, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 19/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 20/108\n",
      "current_iter: 20,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Epoch 00191: reducing learning rate of group 0 to 1.0000e-04.e: 4\n",
      "Early stopping at epoch 195nds - val_loss: 0.005608 - patience: 9\n",
      "\n",
      "Training ended after 240.23 seconds - Best val_loss: 0.005564\n",
      "Best epoch: 186 - Best val_loss: 0.005563938990235329\n",
      "Testing model...\n",
      "Model MSE: 0.005482430569827557, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 20/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 21/108\n",
      "current_iter: 21,hidden_size: 256, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 138nds - val_loss: 0.005870 - patience: 9\n",
      "\n",
      "Training ended after 170.29 seconds - Best val_loss: 0.005815\n",
      "Best epoch: 129 - Best val_loss: 0.005814701318740845\n",
      "Testing model...\n",
      "Model MSE: 0.005611230153590441, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 21/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 22/108\n",
      "current_iter: 22,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 41nds - val_loss: 0.005638 - patience: 9\n",
      "\n",
      "Training ended after 163.39 seconds - Best val_loss: 0.005063\n",
      "Best epoch: 32 - Best val_loss: 0.005063311662524939\n",
      "Testing model...\n",
      "Model MSE: 0.005436173640191555, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 22/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 23/108\n",
      "current_iter: 23,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 34nds - val_loss: 0.006224 - patience: 9\n",
      "\n",
      "Training ended after 133.33 seconds - Best val_loss: 0.005077\n",
      "Best epoch: 25 - Best val_loss: 0.0050769466906785965\n",
      "Testing model...\n",
      "Model MSE: 0.005326204467564821, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 23/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 24/108\n",
      "current_iter: 24,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 72nds - val_loss: 0.005338 - patience: 9\n",
      "\n",
      "Training ended after 284.55 seconds - Best val_loss: 0.005239\n",
      "Best epoch: 63 - Best val_loss: 0.005238738842308521\n",
      "Testing model...\n",
      "Model MSE: 0.005458899773657322, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 24/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 25/108\n",
      "current_iter: 25,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 69nds - val_loss: 0.005488 - patience: 9\n",
      "\n",
      "Training ended after 285.47 seconds - Best val_loss: 0.005421\n",
      "Best epoch: 60 - Best val_loss: 0.0054214149713516235\n",
      "Testing model...\n",
      "Model MSE: 0.005429806187748909, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 25/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 26/108\n",
      "current_iter: 26,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 46nds - val_loss: 0.005847 - patience: 9\n",
      "\n",
      "Training ended after 98.81 seconds - Best val_loss: 0.005208\n",
      "Best epoch: 37 - Best val_loss: 0.0052080899477005005\n",
      "Testing model...\n",
      "Model MSE: 0.005232064053416252, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 26/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 27/108\n",
      "current_iter: 27,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 43nds - val_loss: 0.005537 - patience: 9\n",
      "\n",
      "Training ended after 112.07 seconds - Best val_loss: 0.005397\n",
      "Best epoch: 34 - Best val_loss: 0.005396704189479351\n",
      "Testing model...\n",
      "Model MSE: 0.005397168453782797, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 27/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 28/108\n",
      "current_iter: 28,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 125nds - val_loss: 0.005633 - patience: 9\n",
      "\n",
      "Training ended after 325.51 seconds - Best val_loss: 0.005504\n",
      "Best epoch: 116 - Best val_loss: 0.005503539461642504\n",
      "Testing model...\n",
      "Model MSE: 0.005338520277291536, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 28/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 29/108\n",
      "current_iter: 29,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 146nds - val_loss: 0.005549 - patience: 9\n",
      "\n",
      "Training ended after 375.73 seconds - Best val_loss: 0.005498\n",
      "Best epoch: 137 - Best val_loss: 0.005497685167938471\n",
      "Testing model...\n",
      "Model MSE: 0.0053374189883470535, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 29/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 30/108\n",
      "current_iter: 30,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 46nds - val_loss: 0.005519 - patience: 9\n",
      "\n",
      "Training ended after 64.16 seconds - Best val_loss: 0.005376\n",
      "Best epoch: 37 - Best val_loss: 0.005376101937144995\n",
      "Testing model...\n",
      "Model MSE: 0.00547880120575428, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 30/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 31/108\n",
      "current_iter: 31,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 60nds - val_loss: 0.005463 - patience: 9\n",
      "\n",
      "Training ended after 81.61 seconds - Best val_loss: 0.005380\n",
      "Best epoch: 51 - Best val_loss: 0.00538011034950614\n",
      "Testing model...\n",
      "Model MSE: 0.00549561670050025, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 31/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 32/108\n",
      "current_iter: 32,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 140nds - val_loss: 0.006407 - patience: 9\n",
      "\n",
      "Training ended after 192.77 seconds - Best val_loss: 0.006248\n",
      "Best epoch: 131 - Best val_loss: 0.006248395424336195\n",
      "Testing model...\n",
      "Model MSE: 0.00600583478808403, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 32/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 33/108\n",
      "current_iter: 33,hidden_size: 256, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 112nds - val_loss: 0.006717 - patience: 9\n",
      "\n",
      "Training ended after 154.37 seconds - Best val_loss: 0.006553\n",
      "Best epoch: 103 - Best val_loss: 0.006553142797201872\n",
      "Testing model...\n",
      "Model MSE: 0.0064821806736290455, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 33/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 34/108\n",
      "current_iter: 34,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 33nds - val_loss: 0.005051 - patience: 9\n",
      "\n",
      "Training ended after 120.95 seconds - Best val_loss: 0.004989\n",
      "Best epoch: 24 - Best val_loss: 0.004989041015505791\n",
      "Testing model...\n",
      "Model MSE: 0.0051086461171507835, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 34/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 35/108\n",
      "current_iter: 35,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 29nds - val_loss: 0.005204 - patience: 9\n",
      "\n",
      "Training ended after 105.44 seconds - Best val_loss: 0.005105\n",
      "Best epoch: 20 - Best val_loss: 0.005104504991322756\n",
      "Testing model...\n",
      "Model MSE: 0.005083921365439892, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 35/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 36/108\n",
      "current_iter: 36,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 83nds - val_loss: 0.005116 - patience: 9\n",
      "\n",
      "Training ended after 295.08 seconds - Best val_loss: 0.005058\n",
      "Best epoch: 74 - Best val_loss: 0.005058217793703079\n",
      "Testing model...\n",
      "Model MSE: 0.005193239077925682, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 36/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 37/108\n",
      "current_iter: 37,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 52nds - val_loss: 0.005339 - patience: 9\n",
      "\n",
      "Training ended after 186.58 seconds - Best val_loss: 0.005334\n",
      "Best epoch: 43 - Best val_loss: 0.005334047134965658\n",
      "Testing model...\n",
      "Model MSE: 0.005431944038718939, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 37/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 38/108\n",
      "current_iter: 38,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 45nds - val_loss: 0.005128 - patience: 9\n",
      "\n",
      "Training ended after 84.84 seconds - Best val_loss: 0.004977\n",
      "Best epoch: 36 - Best val_loss: 0.0049767573364079\n",
      "Testing model...\n",
      "Model MSE: 0.005080369766801596, Best MSE: 0.005059551447629929\n",
      "Hyperparameter combination 38/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 39/108\n",
      "current_iter: 39,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 44nds - val_loss: 0.005548 - patience: 9\n",
      "\n",
      "Training ended after 82.44 seconds - Best val_loss: 0.005035\n",
      "Best epoch: 35 - Best val_loss: 0.005034965928643942\n",
      "Testing model...\n",
      "Model MSE: 0.00492987921461463, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 39/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 40/108\n",
      "current_iter: 40,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 103nds - val_loss: 0.005272 - patience: 9\n",
      "\n",
      "Training ended after 190.99 seconds - Best val_loss: 0.005206\n",
      "Best epoch: 94 - Best val_loss: 0.00520579656586051\n",
      "Testing model...\n",
      "Model MSE: 0.005224959459155798, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 40/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 41/108\n",
      "current_iter: 41,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 97nds - val_loss: 0.005353 - patience: 9\n",
      "\n",
      "Training ended after 180.46 seconds - Best val_loss: 0.005341\n",
      "Best epoch: 88 - Best val_loss: 0.005340940319001675\n",
      "Testing model...\n",
      "Model MSE: 0.0053525990806519985, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 41/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 42/108\n",
      "current_iter: 42,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 52nds - val_loss: 0.005353 - patience: 9\n",
      "\n",
      "Training ended after 52.49 seconds - Best val_loss: 0.004915\n",
      "Best epoch: 43 - Best val_loss: 0.004915175959467888\n",
      "Testing model...\n",
      "Model MSE: 0.005048839841037989, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 42/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 43/108\n",
      "current_iter: 43,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 66nds - val_loss: 0.005038 - patience: 9\n",
      "\n",
      "Training ended after 65.02 seconds - Best val_loss: 0.004967\n",
      "Best epoch: 57 - Best val_loss: 0.004966632928699255\n",
      "Testing model...\n",
      "Model MSE: 0.004980570171028376, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 43/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 44/108\n",
      "current_iter: 44,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 178nds - val_loss: 0.005465 - patience: 9\n",
      "\n",
      "Training ended after 173.92 seconds - Best val_loss: 0.005379\n",
      "Best epoch: 169 - Best val_loss: 0.005378974601626396\n",
      "Testing model...\n",
      "Model MSE: 0.005444660317152739, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 44/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 45/108\n",
      "current_iter: 45,hidden_size: 512, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 114nds - val_loss: 0.005532 - patience: 9\n",
      "\n",
      "Training ended after 112.38 seconds - Best val_loss: 0.005491\n",
      "Best epoch: 105 - Best val_loss: 0.00549090513959527\n",
      "Testing model...\n",
      "Model MSE: 0.00571994436904788, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 45/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 46/108\n",
      "current_iter: 46,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 41nds - val_loss: 0.005402 - patience: 9\n",
      "\n",
      "Training ended after 156.30 seconds - Best val_loss: 0.005016\n",
      "Best epoch: 32 - Best val_loss: 0.005016265902668238\n",
      "Testing model...\n",
      "Model MSE: 0.005073642358183861, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 46/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 47/108\n",
      "current_iter: 47,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 42nds - val_loss: 0.006113 - patience: 9\n",
      "\n",
      "Training ended after 159.44 seconds - Best val_loss: 0.004879\n",
      "Best epoch: 33 - Best val_loss: 0.004879098851233721\n",
      "Testing model...\n",
      "Model MSE: 0.005068217869848013, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 47/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 48/108\n",
      "current_iter: 48,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 123nds - val_loss: 0.005155 - patience: 9\n",
      "\n",
      "Training ended after 460.12 seconds - Best val_loss: 0.005090\n",
      "Best epoch: 114 - Best val_loss: 0.005089843645691872\n",
      "Testing model...\n",
      "Model MSE: 0.00497525604441762, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 48/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 49/108\n",
      "current_iter: 49,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 103nds - val_loss: 0.005178 - patience: 9\n",
      "\n",
      "Training ended after 385.61 seconds - Best val_loss: 0.005091\n",
      "Best epoch: 94 - Best val_loss: 0.005090614780783653\n",
      "Testing model...\n",
      "Model MSE: 0.005140736699104309, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 49/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 50/108\n",
      "current_iter: 50,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 40nds - val_loss: 0.005501 - patience: 9\n",
      "\n",
      "Training ended after 79.28 seconds - Best val_loss: 0.005042\n",
      "Best epoch: 31 - Best val_loss: 0.0050422511994838715\n",
      "Testing model...\n",
      "Model MSE: 0.0050436765886843204, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 50/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 51/108\n",
      "current_iter: 51,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 47nds - val_loss: 0.005196 - patience: 9\n",
      "\n",
      "Training ended after 92.53 seconds - Best val_loss: 0.005096\n",
      "Best epoch: 38 - Best val_loss: 0.00509601691737771\n",
      "Testing model...\n",
      "Model MSE: 0.004955606535077095, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 51/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 52/108\n",
      "current_iter: 52,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 91nds - val_loss: 0.005402 - patience: 9\n",
      "\n",
      "Training ended after 178.32 seconds - Best val_loss: 0.005275\n",
      "Best epoch: 82 - Best val_loss: 0.005274896044284105\n",
      "Testing model...\n",
      "Model MSE: 0.00541733531281352, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 52/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 53/108\n",
      "current_iter: 53,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 140nds - val_loss: 0.005108 - patience: 9\n",
      "\n",
      "Training ended after 272.57 seconds - Best val_loss: 0.005031\n",
      "Best epoch: 131 - Best val_loss: 0.0050310431979596615\n",
      "Testing model...\n",
      "Model MSE: 0.005165994632989168, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 53/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 54/108\n",
      "current_iter: 54,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 61nds - val_loss: 0.005529 - patience: 9\n",
      "\n",
      "Training ended after 64.49 seconds - Best val_loss: 0.005011\n",
      "Best epoch: 52 - Best val_loss: 0.0050108893774449825\n",
      "Testing model...\n",
      "Model MSE: 0.005117596592754126, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 54/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 55/108\n",
      "current_iter: 55,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 34nds - val_loss: 0.005325 - patience: 9\n",
      "\n",
      "Training ended after 36.85 seconds - Best val_loss: 0.005264\n",
      "Best epoch: 25 - Best val_loss: 0.005263660568743944\n",
      "Testing model...\n",
      "Model MSE: 0.005348576698452234, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 55/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 56/108\n",
      "current_iter: 56,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 121nds - val_loss: 0.006089 - patience: 9\n",
      "\n",
      "Training ended after 126.96 seconds - Best val_loss: 0.005814\n",
      "Best epoch: 112 - Best val_loss: 0.005813536234200001\n",
      "Testing model...\n",
      "Model MSE: 0.0059052505530416965, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 56/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 57/108\n",
      "current_iter: 57,hidden_size: 512, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 158nds - val_loss: 0.005641 - patience: 9\n",
      "\n",
      "Training ended after 165.25 seconds - Best val_loss: 0.005632\n",
      "Best epoch: 149 - Best val_loss: 0.005631742067635059\n",
      "Testing model...\n",
      "Model MSE: 0.005514477379620075, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 57/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 58/108\n",
      "current_iter: 58,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 30nds - val_loss: 0.005720 - patience: 9\n",
      "\n",
      "Training ended after 131.34 seconds - Best val_loss: 0.005122\n",
      "Best epoch: 21 - Best val_loss: 0.005122023168951273\n",
      "Testing model...\n",
      "Model MSE: 0.005275961477309465, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 58/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 59/108\n",
      "current_iter: 59,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 35nds - val_loss: 0.006446 - patience: 9\n",
      "\n",
      "Training ended after 152.30 seconds - Best val_loss: 0.004995\n",
      "Best epoch: 26 - Best val_loss: 0.004995295312255621\n",
      "Testing model...\n",
      "Model MSE: 0.005269021261483431, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 59/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 60/108\n",
      "current_iter: 60,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 98nds - val_loss: 0.005145 - patience: 9\n",
      "\n",
      "Training ended after 420.59 seconds - Best val_loss: 0.005097\n",
      "Best epoch: 89 - Best val_loss: 0.00509656360372901\n",
      "Testing model...\n",
      "Model MSE: 0.005153332836925983, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 60/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 61/108\n",
      "current_iter: 61,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 91nds - val_loss: 0.005269 - patience: 9\n",
      "\n",
      "Training ended after 390.84 seconds - Best val_loss: 0.005172\n",
      "Best epoch: 82 - Best val_loss: 0.005171594209969044\n",
      "Testing model...\n",
      "Model MSE: 0.0051331655122339725, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 61/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 62/108\n",
      "current_iter: 62,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 32nds - val_loss: 0.004993 - patience: 9\n",
      "\n",
      "Training ended after 72.48 seconds - Best val_loss: 0.004810\n",
      "Best epoch: 23 - Best val_loss: 0.004810096696019173\n",
      "Testing model...\n",
      "Model MSE: 0.005158978048712015, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 62/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 63/108\n",
      "current_iter: 63,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 41nds - val_loss: 0.006103 - patience: 9\n",
      "\n",
      "Training ended after 92.46 seconds - Best val_loss: 0.005008\n",
      "Best epoch: 32 - Best val_loss: 0.005008350126445293\n",
      "Testing model...\n",
      "Model MSE: 0.005251291673630476, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 63/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 64/108\n",
      "current_iter: 64,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 87nds - val_loss: 0.005954 - patience: 9\n",
      "\n",
      "Training ended after 192.91 seconds - Best val_loss: 0.005585\n",
      "Best epoch: 78 - Best val_loss: 0.0055845435708761215\n",
      "Testing model...\n",
      "Model MSE: 0.005697057582437992, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 64/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 65/108\n",
      "current_iter: 65,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 108nds - val_loss: 0.005636 - patience: 9\n",
      "\n",
      "Training ended after 240.04 seconds - Best val_loss: 0.005589\n",
      "Best epoch: 99 - Best val_loss: 0.005588678643107414\n",
      "Testing model...\n",
      "Model MSE: 0.005416467785835266, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 65/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 66/108\n",
      "current_iter: 66,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 62nds - val_loss: 0.005322 - patience: 9\n",
      "\n",
      "Training ended after 73.35 seconds - Best val_loss: 0.005241\n",
      "Best epoch: 53 - Best val_loss: 0.005241332575678825\n",
      "Testing model...\n",
      "Model MSE: 0.005189142655581236, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 66/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 67/108\n",
      "current_iter: 67,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 40nds - val_loss: 0.005622 - patience: 9\n",
      "\n",
      "Training ended after 47.76 seconds - Best val_loss: 0.005172\n",
      "Best epoch: 31 - Best val_loss: 0.005172018427401781\n",
      "Testing model...\n",
      "Model MSE: 0.005330935586243868, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 67/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 68/108\n",
      "current_iter: 68,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 162nds - val_loss: 0.005656 - patience: 9\n",
      "\n",
      "Training ended after 199.61 seconds - Best val_loss: 0.005594\n",
      "Best epoch: 153 - Best val_loss: 0.005593905691057444\n",
      "Testing model...\n",
      "Model MSE: 0.005707296077162027, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 68/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 69/108\n",
      "current_iter: 69,hidden_size: 512, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 109nds - val_loss: 0.006098 - patience: 9\n",
      "\n",
      "Training ended after 128.98 seconds - Best val_loss: 0.006032\n",
      "Best epoch: 100 - Best val_loss: 0.0060323989018797874\n",
      "Testing model...\n",
      "Model MSE: 0.0063273003324866295, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 69/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 70/108\n",
      "current_iter: 70,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 29nds - val_loss: 0.005140 - patience: 9\n",
      "\n",
      "Training ended after 135.88 seconds - Best val_loss: 0.004998\n",
      "Best epoch: 20 - Best val_loss: 0.004997996147722006\n",
      "Testing model...\n",
      "Model MSE: 0.005016725976020098, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 70/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 71/108\n",
      "current_iter: 71,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 22nds - val_loss: 0.005209 - patience: 9\n",
      "\n",
      "Training ended after 103.43 seconds - Best val_loss: 0.005023\n",
      "Best epoch: 13 - Best val_loss: 0.005022830795496702\n",
      "Testing model...\n",
      "Model MSE: 0.00504325982183218, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 71/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 72/108\n",
      "current_iter: 72,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 68nds - val_loss: 0.005375 - patience: 9\n",
      "\n",
      "Training ended after 311.44 seconds - Best val_loss: 0.004979\n",
      "Best epoch: 59 - Best val_loss: 0.004979429766535759\n",
      "Testing model...\n",
      "Model MSE: 0.005174583289772272, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 72/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 73/108\n",
      "current_iter: 73,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 45nds - val_loss: 0.005215 - patience: 9\n",
      "\n",
      "Training ended after 207.29 seconds - Best val_loss: 0.005126\n",
      "Best epoch: 36 - Best val_loss: 0.005126059055328369\n",
      "Testing model...\n",
      "Model MSE: 0.005401190835982561, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 73/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 74/108\n",
      "current_iter: 74,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 59nds - val_loss: 0.004907 - patience: 9\n",
      "\n",
      "Training ended after 138.62 seconds - Best val_loss: 0.004810\n",
      "Best epoch: 50 - Best val_loss: 0.004809618927538395\n",
      "Testing model...\n",
      "Model MSE: 0.004966055974364281, Best MSE: 0.00492987921461463\n",
      "Hyperparameter combination 74/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 75/108\n",
      "current_iter: 75,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 42nds - val_loss: 0.005207 - patience: 9\n",
      "\n",
      "Training ended after 99.99 seconds - Best val_loss: 0.005080\n",
      "Best epoch: 33 - Best val_loss: 0.005079947877675295\n",
      "Testing model...\n",
      "Model MSE: 0.004888792522251606, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 75/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 76/108\n",
      "current_iter: 76,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 87nds - val_loss: 0.005319 - patience: 9\n",
      "\n",
      "Training ended after 203.65 seconds - Best val_loss: 0.005285\n",
      "Best epoch: 78 - Best val_loss: 0.005284725688397884\n",
      "Testing model...\n",
      "Model MSE: 0.00527222128584981, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 76/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 77/108\n",
      "current_iter: 77,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 68nds - val_loss: 0.005426 - patience: 9\n",
      "\n",
      "Training ended after 160.00 seconds - Best val_loss: 0.005295\n",
      "Best epoch: 59 - Best val_loss: 0.005294795613735914\n",
      "Testing model...\n",
      "Model MSE: 0.005364539101719856, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 77/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 78/108\n",
      "current_iter: 78,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 41nds - val_loss: 0.005199 - patience: 9\n",
      "\n",
      "Training ended after 51.71 seconds - Best val_loss: 0.005004\n",
      "Best epoch: 32 - Best val_loss: 0.005004097241908312\n",
      "Testing model...\n",
      "Model MSE: 0.005039168056100607, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 78/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 79/108\n",
      "current_iter: 79,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 49nds - val_loss: 0.005050 - patience: 9\n",
      "\n",
      "Training ended after 61.43 seconds - Best val_loss: 0.004949\n",
      "Best epoch: 40 - Best val_loss: 0.004948548972606659\n",
      "Testing model...\n",
      "Model MSE: 0.00505488459020853, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 79/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 80/108\n",
      "current_iter: 80,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 141nds - val_loss: 0.005698 - patience: 9\n",
      "\n",
      "Training ended after 174.02 seconds - Best val_loss: 0.005435\n",
      "Best epoch: 132 - Best val_loss: 0.00543474406003952\n",
      "Testing model...\n",
      "Model MSE: 0.0054962825961411, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 80/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 81/108\n",
      "current_iter: 81,hidden_size: 1024, depth: 3, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 149nds - val_loss: 0.005193 - patience: 9\n",
      "\n",
      "Training ended after 183.86 seconds - Best val_loss: 0.005153\n",
      "Best epoch: 140 - Best val_loss: 0.00515345623716712\n",
      "Testing model...\n",
      "Model MSE: 0.005539525765925646, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 81/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 82/108\n",
      "current_iter: 82,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 33nds - val_loss: 0.004934 - patience: 9\n",
      "\n",
      "Training ended after 181.52 seconds - Best val_loss: 0.004882\n",
      "Best epoch: 24 - Best val_loss: 0.004881805274635553\n",
      "Testing model...\n",
      "Model MSE: 0.004995686002075672, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 82/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 83/108\n",
      "current_iter: 83,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 35nds - val_loss: 0.005258 - patience: 9\n",
      "\n",
      "Training ended after 192.03 seconds - Best val_loss: 0.004763\n",
      "Best epoch: 26 - Best val_loss: 0.0047633289359509945\n",
      "Testing model...\n",
      "Model MSE: 0.004945003893226385, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 83/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 84/108\n",
      "current_iter: 84,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 53nds - val_loss: 0.005576 - patience: 9\n",
      "\n",
      "Training ended after 287.77 seconds - Best val_loss: 0.005144\n",
      "Best epoch: 44 - Best val_loss: 0.00514420447871089\n",
      "Testing model...\n",
      "Model MSE: 0.005411224439740181, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 84/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 85/108\n",
      "current_iter: 85,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 55nds - val_loss: 0.005430 - patience: 9\n",
      "\n",
      "Training ended after 299.31 seconds - Best val_loss: 0.005166\n",
      "Best epoch: 46 - Best val_loss: 0.005166413262486458\n",
      "Testing model...\n",
      "Model MSE: 0.005427169613540173, Best MSE: 0.004888792522251606\n",
      "Hyperparameter combination 85/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 86/108\n",
      "current_iter: 86,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 53nds - val_loss: 0.004955 - patience: 9\n",
      "\n",
      "Training ended after 148.13 seconds - Best val_loss: 0.004865\n",
      "Best epoch: 44 - Best val_loss: 0.004864873364567757\n",
      "Testing model...\n",
      "Model MSE: 0.004883680492639542, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 86/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 87/108\n",
      "current_iter: 87,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 44nds - val_loss: 0.004839 - patience: 9\n",
      "\n",
      "Training ended after 123.60 seconds - Best val_loss: 0.004747\n",
      "Best epoch: 35 - Best val_loss: 0.004747314378619194\n",
      "Testing model...\n",
      "Model MSE: 0.004984108731150627, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 87/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 88/108\n",
      "current_iter: 88,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 82nds - val_loss: 0.005555 - patience: 9\n",
      "\n",
      "Training ended after 223.01 seconds - Best val_loss: 0.005368\n",
      "Best epoch: 73 - Best val_loss: 0.005368017591536045\n",
      "Testing model...\n",
      "Model MSE: 0.005479143001139164, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 88/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 89/108\n",
      "current_iter: 89,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 104nds - val_loss: 0.005530 - patience: 9\n",
      "\n",
      "Training ended after 281.46 seconds - Best val_loss: 0.005307\n",
      "Best epoch: 95 - Best val_loss: 0.005306640639901161\n",
      "Testing model...\n",
      "Model MSE: 0.005271694622933865, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 89/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 90/108\n",
      "current_iter: 90,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 37nds - val_loss: 0.005754 - patience: 9\n",
      "\n",
      "Training ended after 53.59 seconds - Best val_loss: 0.005095\n",
      "Best epoch: 28 - Best val_loss: 0.005094875581562519\n",
      "Testing model...\n",
      "Model MSE: 0.005095781292766333, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 90/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 91/108\n",
      "current_iter: 91,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 59nds - val_loss: 0.005166 - patience: 9\n",
      "\n",
      "Training ended after 84.64 seconds - Best val_loss: 0.004963\n",
      "Best epoch: 50 - Best val_loss: 0.004962567705661058\n",
      "Testing model...\n",
      "Model MSE: 0.004913948010653257, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 91/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 92/108\n",
      "current_iter: 92,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 160nds - val_loss: 0.005418 - patience: 9\n",
      "\n",
      "Training ended after 226.80 seconds - Best val_loss: 0.005308\n",
      "Best epoch: 151 - Best val_loss: 0.005307664629071951\n",
      "Testing model...\n",
      "Model MSE: 0.00547835323959589, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 92/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 93/108\n",
      "current_iter: 93,hidden_size: 1024, depth: 4, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 94nds - val_loss: 0.006106 - patience: 9\n",
      "\n",
      "Training ended after 134.00 seconds - Best val_loss: 0.005962\n",
      "Best epoch: 85 - Best val_loss: 0.005961806047707796\n",
      "Testing model...\n",
      "Model MSE: 0.005976543296128511, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 93/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 94/108\n",
      "current_iter: 94,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 21nds - val_loss: 0.005390 - patience: 9\n",
      "\n",
      "Training ended after 131.22 seconds - Best val_loss: 0.005113\n",
      "Best epoch: 12 - Best val_loss: 0.005113385617733002\n",
      "Testing model...\n",
      "Model MSE: 0.0052147419191896915, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 94/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 95/108\n",
      "current_iter: 95,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 34nds - val_loss: 0.006188 - patience: 9\n",
      "\n",
      "Training ended after 208.90 seconds - Best val_loss: 0.004932\n",
      "Best epoch: 25 - Best val_loss: 0.0049318489618599415\n",
      "Testing model...\n",
      "Model MSE: 0.004994196817278862, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 95/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 96/108\n",
      "current_iter: 96,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 32nds - val_loss: 0.006082 - patience: 9\n",
      "\n",
      "Training ended after 197.12 seconds - Best val_loss: 0.006052\n",
      "Best epoch: 23 - Best val_loss: 0.006052100565284491\n",
      "Testing model...\n",
      "Model MSE: 0.006055264268070459, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 96/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 97/108\n",
      "current_iter: 97,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 8, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 78nds - val_loss: 0.005324 - patience: 9\n",
      "\n",
      "Training ended after 474.29 seconds - Best val_loss: 0.005089\n",
      "Best epoch: 69 - Best val_loss: 0.005088677629828453\n",
      "Testing model...\n",
      "Model MSE: 0.005169835407286882, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 97/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 98/108\n",
      "current_iter: 98,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 39nds - val_loss: 0.005360 - patience: 9\n",
      "\n",
      "Training ended after 122.01 seconds - Best val_loss: 0.004943\n",
      "Best epoch: 30 - Best val_loss: 0.004942723084241152\n",
      "Testing model...\n",
      "Model MSE: 0.004988295491784811, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 98/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 99/108\n",
      "current_iter: 99,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 33nds - val_loss: 0.005662 - patience: 9\n",
      "\n",
      "Training ended after 103.76 seconds - Best val_loss: 0.005123\n",
      "Best epoch: 24 - Best val_loss: 0.005122775211930275\n",
      "Testing model...\n",
      "Model MSE: 0.005022063851356506, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 99/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 100/108\n",
      "current_iter: 100,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 103nds - val_loss: 0.005407 - patience: 9\n",
      "\n",
      "Training ended after 317.12 seconds - Best val_loss: 0.005361\n",
      "Best epoch: 94 - Best val_loss: 0.005360806360840797\n",
      "Testing model...\n",
      "Model MSE: 0.005446979776024818, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 100/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 101/108\n",
      "current_iter: 101,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 16, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 85nds - val_loss: 0.005823 - patience: 9\n",
      "\n",
      "Training ended after 262.63 seconds - Best val_loss: 0.005587\n",
      "Best epoch: 76 - Best val_loss: 0.0055872309021651745\n",
      "Testing model...\n",
      "Model MSE: 0.005486821755766869, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 101/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 102/108\n",
      "current_iter: 102,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 40nds - val_loss: 0.004976 - patience: 9\n",
      "\n",
      "Training ended after 65.05 seconds - Best val_loss: 0.004836\n",
      "Best epoch: 31 - Best val_loss: 0.004835532978177071\n",
      "Testing model...\n",
      "Model MSE: 0.005067647900432348, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 102/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 103/108\n",
      "current_iter: 103,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.01, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 65nds - val_loss: 0.005000 - patience: 9\n",
      "\n",
      "Training ended after 104.78 seconds - Best val_loss: 0.004907\n",
      "Best epoch: 56 - Best val_loss: 0.004907489288598299\n",
      "Testing model...\n",
      "Model MSE: 0.005094308406114578, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 103/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 104/108\n",
      "current_iter: 104,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 10, momentum: 0.9\n",
      "Early stopping at epoch 104nds - val_loss: 0.006100 - patience: 9\n",
      "\n",
      "Training ended after 167.12 seconds - Best val_loss: 0.005929\n",
      "Best epoch: 95 - Best val_loss: 0.00592900300398469\n",
      "Testing model...\n",
      "Model MSE: 0.005909086670726538, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 104/108 finished\n",
      "\n",
      "\n",
      "Hyperparameter combination 105/108\n",
      "current_iter: 105,hidden_size: 1024, depth: 5, num_epochs: 200, batch_size: 32, lr: 0.001, step_size: 20, momentum: 0.9\n",
      "Early stopping at epoch 130nds - val_loss: 0.005834 - patience: 9\n",
      "\n",
      "Training ended after 209.57 seconds - Best val_loss: 0.005755\n",
      "Best epoch: 121 - Best val_loss: 0.005755139514803886\n",
      "Testing model...\n",
      "Model MSE: 0.005792100913822651, Best MSE: 0.004883680492639542\n",
      "Hyperparameter combination 105/108 finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grid search loop\n",
    "best_mse = float('inf')\n",
    "current_iter = 0\n",
    "for i, (hidden_size, depth, num_epochs, batch, lr, step_size, momentum) in enumerate(hyperparameters):\n",
    "    current_iter += 1\n",
    "    print(f'\\nHyperparameter combination {i+1}/{n_comb}')\n",
    "    print(f'current_iter: {current_iter},hidden_size: {hidden_size}, depth: {depth}, num_epochs: {num_epochs}, batch_size: {batch}, lr: {lr}, step_size: {step_size}, momentum: {momentum}')\n",
    "    writer = SummaryWriter(f'runs/hidden_size={hidden_size}, depth={depth}, num_epochs={num_epochs}, batch_size={batch}, lr={lr}, step_size={step_size}, momentum={momentum}')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(Y_train, dtype=torch.float32)), batch_size=batch, shuffle=True)\n",
    "    model = get_model(X_train.shape[1], hidden_size, dropout_prob, depth).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=step_size, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "    model, best_epoch, best_loss = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, writer, device, patience, num_epochs)\n",
    "   \n",
    "    \n",
    "    print(f'Best epoch: {best_epoch+1} - Best val_loss: {best_loss}')\n",
    "    print(f'Testing model...')\n",
    "    test_loss = test_model(model, test_loader, criterion, device)\n",
    "    writer.add_hparams({'hidden_size': hidden_size, 'depth': depth, 'batch': batch,'lr': lr, 'step_size': step_size, 'momentum': momentum}, {'hparam/mse': test_loss})\n",
    "    if test_loss < best_mse:\n",
    "        best_mse = test_loss\n",
    "        best_model = model\n",
    "        \n",
    "        history_loss = best_epoch\n",
    "        history_val_loss = best_loss\n",
    "\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        # save config\n",
    "        with open('best_model_config.json', 'w') as f:\n",
    "            json.dump({'hidden_size': hidden_size, 'depth': depth, 'num_epochs': num_epochs, 'batch': batch,\n",
    "                       'lr': lr, 'step_size': step_size}, f)   \n",
    "\n",
    "    writer.flush()\n",
    "    print(f'Model MSE: {test_loss}, Best MSE: {best_mse}')\n",
    "    print(f'Hyperparameter combination {i+1}/{n_comb} finished\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model - MSE: 0.004884\n",
      "R2: 0.978349 - MSE: 0.004884\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion =  torch.nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "with open('best_model_config.json', 'r') as f:\n",
    "        best_model_config = json.load(f)\n",
    "\n",
    "best_model = get_model(X_train.shape[1], best_model_config['hidden_size'], dropout_prob, best_model_config['depth'])\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "# evaluate best model\n",
    "best_mse,y_pred,y_true= test_model(best_model, criterion, test_loader,device)   \n",
    "print(\"Best model - MSE: {:.6f}\".format(best_mse))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "print(\"R2: {:.6f} - MSE: {:.6f}\".format(r2, mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'MSELoss' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _, y_pred, y_true \u001b[39m=\u001b[39m test_model(best_model, criterion, test_loader,device)\n\u001b[0;32m      2\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      3\u001b[0m y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "Cell \u001b[1;32mIn[11], line 51\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(model, test_loader, criterion, device)\u001b[0m\n\u001b[0;32m     49\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m     50\u001b[0m test_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 51\u001b[0m \u001b[39mfor\u001b[39;00m X, Y \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m     52\u001b[0m     X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     53\u001b[0m     Y \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'MSELoss' object is not iterable"
     ]
    }
   ],
   "source": [
    "_, y_pred, y_true = test_model(best_model, criterion, test_loader,device)\n",
    "y_pred = y_pred.squeeze().cpu().detach().numpy()\n",
    "y_true = y_true.squeeze().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
